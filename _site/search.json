[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Topics",
    "section": "",
    "text": "Hello Blog!\n\n\n\n\n\n\n\n\nOct 25, 2025\n\n\nPatrick Linke\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\nPredicting Medical Costs - A Regression Problem\n\n\n\nRegression\n\nMedicine\n\n\n\n\n\n\n\n\n\nOct 26, 2025\n\n\nPatrick Linke\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#quarto",
    "href": "index.html#quarto",
    "title": "blog",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "posts/test_folder/test.html",
    "href": "posts/test_folder/test.html",
    "title": "Linear Regression — First Steps",
    "section": "",
    "text": "print(\"hello\")\n\nhello\n\n\nprint(“hello)"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Topics",
    "section": "",
    "text": "Hello Blog!\n\n\n\n\n\n\n\n\nOct 25, 2025\n\n\nPatrick Linke\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\nPredicting Medical Costs - A Regression Problem\n\n\n\nRegression\n\nMedical\n\n\n\n\n\n\n\n\n\nOct 25, 2025\n\n\nPatrick Linke\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/01_Medical_Costs_Regression/Regression_project.html",
    "href": "posts/01_Medical_Costs_Regression/Regression_project.html",
    "title": "Medical Costs - A Regression Task",
    "section": "",
    "text": "This notebook contains a regression project on the “Medical Cost Personal Datasets” dataset (url=https://www.kaggle.com/datasets/mirichoi0218/insurance)\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor, plot_tree\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble import VotingRegressor\n\n\ndf = pd.read_csv(\"../data/insurance.csv\")\n\n\ndf.head()\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n0\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.92400\n\n\n1\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.55230\n\n\n2\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.46200\n\n\n3\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.47061\n\n\n4\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.85520\n\n\n\n\n\n\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 7 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       1338 non-null   int64  \n 1   sex       1338 non-null   object \n 2   bmi       1338 non-null   float64\n 3   children  1338 non-null   int64  \n 4   smoker    1338 non-null   object \n 5   region    1338 non-null   object \n 6   charges   1338 non-null   float64\ndtypes: float64(2), int64(2), object(3)\nmemory usage: 73.3+ KB\n\n\n\n# check for missing values\n# -&gt; no missing values\ndf.isnull().sum()\n\nage         0\nsex         0\nbmi         0\nchildren    0\nsmoker      0\nregion      0\ncharges     0\ndtype: int64\n\n\n\naxes = df.hist(bins=50, density=True, figsize=(10,8), color=\"#0071E3\")\nfor ax in axes.ravel():\n    if ax is None:\n        continue\n    col = ax.get_title()\n    if col in df.select_dtypes(\"number\"):\n        df[col].plot(kind=\"kde\", ax=ax, color=\"#BF5AF2\", linewidth=2.6)\n    \n    ax.set_xlim(0)\n    ax.grid()\n    ax.set_facecolor(\"white\")\n\n    ax.set_title(\n        ax.get_title().capitalize(),\n        fontsize=16,\n        fontweight=\"semibold\",\n        color=\"#1D1D1F\",\n        pad=18,\n    )\n    \n\n\n\n\n\n\n\n\n\ndf[\"region\"].value_counts()\n\nregion\nsoutheast    364\nsouthwest    325\nnorthwest    325\nnortheast    324\nName: count, dtype: int64\n\n\n\ndf[\"sex\"].value_counts()\n\nsex\nmale      676\nfemale    662\nName: count, dtype: int64\n\n\n\ndf[\"smoker\"].value_counts()\n\nsmoker\nno     1064\nyes     274\nName: count, dtype: int64\n\n\n\n# Insights:\n# Charges generally rise with age\n# Three nearly parallel bands (different categories)\n# Smokers have higher charges than non-smokers\n\nsns.scatterplot(df, x=\"age\", y=\"charges\", alpha=0.5, hue=\"smoker\", palette=\"colorblind\")\nplt.legend(loc=[1.02,0.8])\n\n\n\n\n\n\n\n\n\n# Insights:\n# Charges generally rise with BMI\n# Smokers have higher charges than non-smokers\n\nsns.scatterplot(df, x=\"bmi\", y=\"charges\", alpha=0.5, hue=\"smoker\", palette=\"colorblind\") # higher BMI -&gt; higher charges\n\n\n\n\n\n\n\n\n\n# Insights:\n# Charges correlates to being a smoker and age quite strongly\n\ndf[\"smoker_flag\"] = df[\"smoker\"].map({\"yes\": 1, \"no\": 0})\ndf[\"sex_flag\"] = df[\"sex\"].map({\"female\": 0, \"male\": 1})\ndf.corr(numeric_only=True)[\"charges\"].sort_values(ascending=False)\n\ncharges        1.000000\nsmoker_flag    0.787251\nage            0.299008\nbmi            0.198341\nchildren       0.067998\nsex_flag       0.057292\nName: charges, dtype: float64\n\n\n\n\n\n\ndf = pd.read_csv(\"../data/insurance.csv\")\n\n\ndf.head()\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n0\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.92400\n\n\n1\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.55230\n\n\n2\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.46200\n\n\n3\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.47061\n\n\n4\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.85520\n\n\n\n\n\n\n\n\nnum_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"scaler\", StandardScaler())\n])\n\ncat_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"onehot\", OneHotEncoder(drop=\"if_binary\"))\n])\n\n\nfrom sklearn.compose import ColumnTransformer, make_column_selector\n\n\npreprocessing = ColumnTransformer([\n    (\"num\", num_pipeline, make_column_selector(dtype_include=np.number)),\n    (\"cat\", cat_pipeline, make_column_selector(dtype_include=object))\n])\n\n\n\n\nX = df.drop(\"charges\", axis=1)\n\n\ny = df[\"charges\"]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n\n\nprint(f\"X_train: {X_train.shape}; y_train: {y_train.shape}\\nX_val: {X_val.shape}; y_val: {y_val.shape}\\nX_test: {X_test.shape}; y_test: {y_test.shape}\")\n\nX_train: (795, 6); y_train: (795,)\nX_val: (342, 6); y_val: (342,)\nX_test: (201, 6); y_test: (201,)\n\n\n\n\n\n\n\ndef metrics(y_true, y_pred):\n    MAE = mean_absolute_error(y_true, y_pred)\n    print(f\"MAE: {MAE}\")\n\n    MSE = mean_squared_error(y_true, y_pred)\n    RMSE = np.sqrt(MSE)\n    print(f\"MSE: {MSE}\\nRMSE: {RMSE}\")\n\n\n\n\nlinear_reg = make_pipeline(preprocessing, LinearRegression())\nlinear_reg.fit(X_train, y_train)\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('linearregression', LinearRegression())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('linearregression', LinearRegression())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')LinearRegressionLinearRegression()\n\n\n\ny_pred = linear_reg.predict(X_val)\n\n\nmetrics(y_val, y_pred)\n\nMAE: 4169.607569411409\nMSE: 36406996.983101465\nRMSE: 6033.821093063786\n\n\n\nscore = -cross_val_score(linear_reg, X_train, y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(score).describe()\n\ncount      10.000000\nmean     6223.816156\nstd       811.221206\nmin      5367.259534\n25%      5738.071105\n50%      5967.331953\n75%      6367.402518\nmax      7976.511184\ndtype: float64\n\n\n\n\n\n\nsvr_model = make_pipeline(preprocessing, SVR())\nsvr_model.fit(X_train, y_train)\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                ('svr', SVR())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                ('svr', SVR())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')SVRSVR()\n\n\n\ny_pred = svr_model.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 7814.88732173058\nMSE: 149910137.451377\nRMSE: 12243.77954111299\n\n\n\nparam_grid = {\n    \"svr__C\": [0.1, 1, 10, 100, 1000],\n    \"svr__gamma\": ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n    \"svr__kernel\": ['rbf', 'poly', 'sigmoid', 'linear'],\n    \"svr__epsilon\": [0.01, 0.1, 0.2, 0.5]\n}\n\nsvr_tuned = RandomizedSearchCV(svr_model, param_distributions=param_grid, n_iter=30, cv=3, scoring=\"neg_root_mean_squared_error\", random_state=42, n_jobs=-1, verbose=2)\n\nsvr_tuned.fit(X_train, y_train)\n\nFitting 3 folds for each of 30 candidates, totalling 90 fits\n\n\nRandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                                             ('svr', SVR())]),\n                   n_iter=30, n_jobs=-1,\n                   param_distributions={'svr__C': [0.1, 1, 10, 100, 1000],\n                                        'svr__epsilon': [0.01, 0.1, 0.2, 0.5],\n                                        'svr__gamma': ['scale', 'auto', 0.001,\n                                                       0.01, 0.1, 1],\n                                        'svr__kernel': ['rbf', 'poly',\n                                                        'sigmoid', 'linear']},\n                   random_state=42, scoring='neg_root_mean_squared_error',\n                   verbose=2)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                                             ('svr', SVR())]),\n                   n_iter=30, n_jobs=-1,\n                   param_distributions={'svr__C': [0.1, 1, 10, 100, 1000],\n                                        'svr__epsilon': [0.01, 0.1, 0.2, 0.5],\n                                        'svr__gamma': ['scale', 'auto', 0.001,\n                                                       0.01, 0.1, 1],\n                                        'svr__kernel': ['rbf', 'poly',\n                                                        'sigmoid', 'linear']},\n                   random_state=42, scoring='neg_root_mean_squared_error',\n                   verbose=2)estimator: PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                ('svr', SVR())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')SVRSVR()\n\n\n\n-svr_tuned.best_score_\n\n7645.012433741977\n\n\n\nsvr_tuned.best_params_\n\n{'svr__kernel': 'linear',\n 'svr__gamma': 0.01,\n 'svr__epsilon': 0.1,\n 'svr__C': 1000}\n\n\n\n\n\nUsing a simple DecisionTree as a baseline\n\ndt = make_pipeline(preprocessing, DecisionTreeRegressor(max_depth=3))\ndt.fit(X_train, y_train)\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('decisiontreeregressor', DecisionTreeRegressor(max_depth=3))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('decisiontreeregressor', DecisionTreeRegressor(max_depth=3))])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')DecisionTreeRegressorDecisionTreeRegressor(max_depth=3)\n\n\n\ny_pred = dt.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2777.9817164081323\nMSE: 20510058.067987088\nRMSE: 4528.803160658133\n\n\n\nscore = -cross_val_score(dt, X_train, y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(score).describe()\n\ncount      10.000000\nmean     4886.767496\nstd      1067.531833\nmin      3721.684778\n25%      4133.296988\n50%      4587.401285\n75%      5037.971872\nmax      6835.741056\ndtype: float64\n\n\n\nfeature_names = dt[\"columntransformer\"].get_feature_names_out()\n\n\n# Insights:\n# First splits on smoking -&gt;  confirming smoking dominates the cost signal\n# For the smokers, BMI is the next important factor\n# For non-smokers age is the next important factor\n\nplt.figure(figsize=(14, 10))\nplot_tree(\n    dt[\"decisiontreeregressor\"],\n     max_depth=4,\n     feature_names=feature_names,\n     filled=True,\n     rounded=True,\n     fontsize=10,\n     \n);\n\n\n\n\n\n\n\n\nUsing RandomizedSearch to find the best parameters for the Decisiontree\n\nparam_grid = {\n    \"decisiontreeregressor__max_depth\": range(2,20),\n    \"decisiontreeregressor__min_samples_split\": range(2,10),\n    \"decisiontreeregressor__min_samples_leaf\": range(1,10),\n    \"decisiontreeregressor__max_features\": [\"sqrt\", \"log2\", None]\n}\n\nrnd_decision_tree = RandomizedSearchCV(dt, param_distributions=param_grid, n_iter=100, scoring=\"neg_root_mean_squared_error\", random_state=42)\n\nrnd_decision_tree.fit(X_train, y_train)\n\nRandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequ...\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=3))]),\n                   n_iter=100,\n                   param_distributions={'decisiontreeregressor__max_depth': range(2, 20),\n                                        'decisiontreeregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'decisiontreeregressor__min_samples_leaf': range(1, 10),\n                                        'decisiontreeregressor__min_samples_split': range(2, 10)},\n                   random_state=42, scoring='neg_root_mean_squared_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequ...\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=3))]),\n                   n_iter=100,\n                   param_distributions={'decisiontreeregressor__max_depth': range(2, 20),\n                                        'decisiontreeregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'decisiontreeregressor__min_samples_leaf': range(1, 10),\n                                        'decisiontreeregressor__min_samples_split': range(2, 10)},\n                   random_state=42, scoring='neg_root_mean_squared_error')estimator: PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('decisiontreeregressor', DecisionTreeRegressor(max_depth=3))])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')DecisionTreeRegressorDecisionTreeRegressor(max_depth=3)\n\n\n\nrnd_decision_tree.best_params_\n\n{'decisiontreeregressor__min_samples_split': 4,\n 'decisiontreeregressor__min_samples_leaf': 9,\n 'decisiontreeregressor__max_features': None,\n 'decisiontreeregressor__max_depth': 4}\n\n\n\n-rnd_decision_tree.best_score_\n\n4816.461448818147\n\n\n\n# get a dataframe to show the training steps\n\nresults = pd.DataFrame(rnd_decision_tree.cv_results_)\n\n\nresults.head()\n\n\n\n\n\n\n\n\nmean_fit_time\nstd_fit_time\nmean_score_time\nstd_score_time\nparam_decisiontreeregressor__min_samples_split\nparam_decisiontreeregressor__min_samples_leaf\nparam_decisiontreeregressor__max_features\nparam_decisiontreeregressor__max_depth\nparams\nsplit0_test_score\nsplit1_test_score\nsplit2_test_score\nsplit3_test_score\nsplit4_test_score\nmean_test_score\nstd_test_score\nrank_test_score\n\n\n\n\n0\n0.008926\n0.001661\n0.004743\n0.002596\n2\n7\nNone\n19\n{'decisiontreeregressor__min_samples_split': 2...\n-6551.530702\n-4903.348250\n-4728.680073\n-5088.961025\n-4825.766404\n-5219.657291\n676.347302\n20\n\n\n1\n0.009064\n0.002511\n0.002820\n0.000438\n8\n2\nNone\n12\n{'decisiontreeregressor__min_samples_split': 8...\n-7242.564503\n-5128.548712\n-5189.496060\n-5399.390140\n-5370.049948\n-5666.009872\n795.000978\n33\n\n\n2\n0.005586\n0.000597\n0.002515\n0.000449\n7\n7\nsqrt\n13\n{'decisiontreeregressor__min_samples_split': 7...\n-7521.892916\n-5535.560296\n-10098.621144\n-5366.315712\n-4670.216493\n-6638.521312\n1972.911057\n57\n\n\n3\n0.007372\n0.000837\n0.002854\n0.000594\n5\n2\nNone\n13\n{'decisiontreeregressor__min_samples_split': 5...\n-7345.571759\n-5247.115430\n-5481.319187\n-5497.099554\n-5259.014318\n-5766.024049\n796.827865\n37\n\n\n4\n0.005022\n0.000546\n0.001917\n0.000193\n5\n4\nlog2\n3\n{'decisiontreeregressor__min_samples_split': 5...\n-10542.289822\n-5828.920153\n-7994.586393\n-10095.531506\n-7422.950625\n-8376.855700\n1743.042841\n97\n\n\n\n\n\n\n\n\ny_pred = rnd_decision_tree.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2562.7198812363467\nMSE: 18807488.914763357\nRMSE: 4336.76018644833\n\n\n\nModel error is reasonably low versus the data scale: MAE ≈ 2.6 k on mean charges ≈ 13.3 k (≈19 % relative), and RMSE 4.3 k is well below the dataset’s standard deviation (12.1 k), so the model captures most variance.\nBaseline check: always predicting the mean would give RMSE ≈ 12.1 k; your MSE of 18.8 M implies R² ≈ 0.87, meaning the tree explains roughly 87 % of the variation—strong for a single decision tree.\n\n\ndf[\"charges\"].describe()\n\ncount     1338.000000\nmean     13270.422265\nstd      12110.011237\nmin       1121.873900\n25%       4740.287150\n50%       9382.033000\n75%      16639.912515\nmax      63770.428010\nName: charges, dtype: float64\n\n\nPlot the best DecisionTree\n\nbest_tree = rnd_decision_tree.best_estimator_[\"decisiontreeregressor\"]\nbest_tree\n\nDecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=4)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.DecisionTreeRegressorDecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=4)\n\n\n\nplt.figure(figsize=(14, 10))\nplot_tree(\n     best_tree,\n     max_depth=4,\n     feature_names=feature_names,\n     filled=True,\n     rounded=True,\n     fontsize=10,\n     \n);\n\n\n\n\n\n\n\n\n\n\n\n\nrfr = make_pipeline(preprocessing, RandomForestRegressor())\nrfr.fit(X_train, y_train)\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])),\n                ('randomforestregressor', RandomForestRegressor())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])),\n                ('randomforestregressor', RandomForestRegressor())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')RandomForestRegressorRandomForestRegressor()\n\n\n\ny_pred = rfr.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2572.108498414695\nMSE: 22204912.574424837\nRMSE: 4712.208884846345\n\n\n\nscore = -cross_val_score(rfr, X_train, y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(score).describe()\n\ncount      10.000000\nmean     4999.162702\nstd       933.832049\nmin      4183.865103\n25%      4276.681296\n50%      4665.735171\n75%      5326.890498\nmax      6894.202512\ndtype: float64\n\n\n\n\nparam_grid = {\n    \"randomforestregressor__n_estimators\": range(50,200),\n    \"randomforestregressor__max_depth\": range(2,40),\n    \"randomforestregressor__min_samples_split\": range(2,10),\n    \"randomforestregressor__min_samples_leaf\": range(1,10),\n    \"randomforestregressor__max_features\": [\"sqrt\", \"log2\", None]\n}\n\nrnd_forest = RandomizedSearchCV(rfr, param_distributions=param_grid, n_iter=100, scoring=\"neg_root_mean_squared_error\", random_state=42)\n\nrnd_forest.fit(X_train, y_train)\n\nRandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequ...\n                   n_iter=100,\n                   param_distributions={'randomforestregressor__max_depth': range(2, 40),\n                                        'randomforestregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'randomforestregressor__min_samples_leaf': range(1, 10),\n                                        'randomforestregressor__min_samples_split': range(2, 10),\n                                        'randomforestregressor__n_estimators': range(50, 200)},\n                   random_state=42, scoring='neg_root_mean_squared_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequ...\n                   n_iter=100,\n                   param_distributions={'randomforestregressor__max_depth': range(2, 40),\n                                        'randomforestregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'randomforestregressor__min_samples_leaf': range(1, 10),\n                                        'randomforestregressor__min_samples_split': range(2, 10),\n                                        'randomforestregressor__n_estimators': range(50, 200)},\n                   random_state=42, scoring='neg_root_mean_squared_error')estimator: PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])),\n                ('randomforestregressor', RandomForestRegressor())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')RandomForestRegressorRandomForestRegressor()\n\n\n\nrnd_forest.best_params_\n\n{'randomforestregressor__n_estimators': 58,\n 'randomforestregressor__min_samples_split': 7,\n 'randomforestregressor__min_samples_leaf': 3,\n 'randomforestregressor__max_features': None,\n 'randomforestregressor__max_depth': 5}\n\n\n\n-rnd_forest.best_score_\n\n4704.255477078022\n\n\n\ny_pred = rnd_forest.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2481.440427770899\nMSE: 19115754.99090381\nRMSE: 4372.156789377962\n\n\n\n\n\n\n\n# Combine the best models\nensemble = VotingRegressor([\n    ('rf', make_pipeline(preprocessing, RandomForestRegressor(n_estimators=58, min_samples_split=7, min_samples_leaf=3, max_features=None, max_depth=5))),\n    ('dt', make_pipeline(preprocessing, DecisionTreeRegressor(min_samples_split=4, min_samples_leaf=9, max_features=None, max_depth=4))),\n    #('linear', make_pipeline(preprocessing, LinearRegression()))\n])\n\n\nensemble.fit(X_train, y_train)\n\nVotingRegressor(estimators=[('rf',\n                             Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequent')),\n                                                                                               ('onehot',\n                                                                                                OneHotEncoder(drop='if_binary'))]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=4,\n                                                                    min_samples_leaf=9,\n                                                                    min_samples_split=4))]))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.VotingRegressorVotingRegressor(estimators=[('rf',\n                             Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequent')),\n                                                                                               ('onehot',\n                                                                                                OneHotEncoder(drop='if_binary'))]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=4,\n                                                                    min_samples_leaf=9,\n                                                                    min_samples_split=4))]))])rfcolumntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')RandomForestRegressorRandomForestRegressor(max_depth=5, max_features=None, min_samples_leaf=3,\n                      min_samples_split=7, n_estimators=58)dtcolumntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')DecisionTreeRegressorDecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=4)\n\n\n\ny_pred = ensemble.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2480.1281238058236\nMSE: 18658891.89670748\nRMSE: 4319.59395044343\n\n\n\nscore = -cross_val_score(ensemble, X_train, y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(score).describe()\n\ncount      10.000000\nmean     4684.677748\nstd       975.940466\nmin      3759.443539\n25%      3969.849999\n50%      4450.199162\n75%      4785.729508\nmax      6575.824841\ndtype: float64"
  },
  {
    "objectID": "posts/01_Medical_Costs_Regression/Regression_project.html#eda",
    "href": "posts/01_Medical_Costs_Regression/Regression_project.html#eda",
    "title": "Medical Costs - A Regression Task",
    "section": "",
    "text": "df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 7 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       1338 non-null   int64  \n 1   sex       1338 non-null   object \n 2   bmi       1338 non-null   float64\n 3   children  1338 non-null   int64  \n 4   smoker    1338 non-null   object \n 5   region    1338 non-null   object \n 6   charges   1338 non-null   float64\ndtypes: float64(2), int64(2), object(3)\nmemory usage: 73.3+ KB\n\n\n\n# check for missing values\n# -&gt; no missing values\ndf.isnull().sum()\n\nage         0\nsex         0\nbmi         0\nchildren    0\nsmoker      0\nregion      0\ncharges     0\ndtype: int64\n\n\n\naxes = df.hist(bins=50, density=True, figsize=(10,8), color=\"#0071E3\")\nfor ax in axes.ravel():\n    if ax is None:\n        continue\n    col = ax.get_title()\n    if col in df.select_dtypes(\"number\"):\n        df[col].plot(kind=\"kde\", ax=ax, color=\"#BF5AF2\", linewidth=2.6)\n    \n    ax.set_xlim(0)\n    ax.grid()\n    ax.set_facecolor(\"white\")\n\n    ax.set_title(\n        ax.get_title().capitalize(),\n        fontsize=16,\n        fontweight=\"semibold\",\n        color=\"#1D1D1F\",\n        pad=18,\n    )\n    \n\n\n\n\n\n\n\n\n\ndf[\"region\"].value_counts()\n\nregion\nsoutheast    364\nsouthwest    325\nnorthwest    325\nnortheast    324\nName: count, dtype: int64\n\n\n\ndf[\"sex\"].value_counts()\n\nsex\nmale      676\nfemale    662\nName: count, dtype: int64\n\n\n\ndf[\"smoker\"].value_counts()\n\nsmoker\nno     1064\nyes     274\nName: count, dtype: int64\n\n\n\n# Insights:\n# Charges generally rise with age\n# Three nearly parallel bands (different categories)\n# Smokers have higher charges than non-smokers\n\nsns.scatterplot(df, x=\"age\", y=\"charges\", alpha=0.5, hue=\"smoker\", palette=\"colorblind\")\nplt.legend(loc=[1.02,0.8])\n\n\n\n\n\n\n\n\n\n# Insights:\n# Charges generally rise with BMI\n# Smokers have higher charges than non-smokers\n\nsns.scatterplot(df, x=\"bmi\", y=\"charges\", alpha=0.5, hue=\"smoker\", palette=\"colorblind\") # higher BMI -&gt; higher charges\n\n\n\n\n\n\n\n\n\n# Insights:\n# Charges correlates to being a smoker and age quite strongly\n\ndf[\"smoker_flag\"] = df[\"smoker\"].map({\"yes\": 1, \"no\": 0})\ndf[\"sex_flag\"] = df[\"sex\"].map({\"female\": 0, \"male\": 1})\ndf.corr(numeric_only=True)[\"charges\"].sort_values(ascending=False)\n\ncharges        1.000000\nsmoker_flag    0.787251\nage            0.299008\nbmi            0.198341\nchildren       0.067998\nsex_flag       0.057292\nName: charges, dtype: float64"
  },
  {
    "objectID": "posts/01_Medical_Costs_Regression/Regression_project.html#preprocessing",
    "href": "posts/01_Medical_Costs_Regression/Regression_project.html#preprocessing",
    "title": "Medical Costs - A Regression Task",
    "section": "",
    "text": "df = pd.read_csv(\"../data/insurance.csv\")\n\n\ndf.head()\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n0\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.92400\n\n\n1\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.55230\n\n\n2\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.46200\n\n\n3\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.47061\n\n\n4\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.85520\n\n\n\n\n\n\n\n\nnum_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"scaler\", StandardScaler())\n])\n\ncat_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"onehot\", OneHotEncoder(drop=\"if_binary\"))\n])\n\n\nfrom sklearn.compose import ColumnTransformer, make_column_selector\n\n\npreprocessing = ColumnTransformer([\n    (\"num\", num_pipeline, make_column_selector(dtype_include=np.number)),\n    (\"cat\", cat_pipeline, make_column_selector(dtype_include=object))\n])\n\n\n\n\nX = df.drop(\"charges\", axis=1)\n\n\ny = df[\"charges\"]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n\n\nprint(f\"X_train: {X_train.shape}; y_train: {y_train.shape}\\nX_val: {X_val.shape}; y_val: {y_val.shape}\\nX_test: {X_test.shape}; y_test: {y_test.shape}\")\n\nX_train: (795, 6); y_train: (795,)\nX_val: (342, 6); y_val: (342,)\nX_test: (201, 6); y_test: (201,)"
  },
  {
    "objectID": "posts/01_Medical_Costs_Regression/Regression_project.html#training-a-model",
    "href": "posts/01_Medical_Costs_Regression/Regression_project.html#training-a-model",
    "title": "Medical Costs - A Regression Task",
    "section": "",
    "text": "def metrics(y_true, y_pred):\n    MAE = mean_absolute_error(y_true, y_pred)\n    print(f\"MAE: {MAE}\")\n\n    MSE = mean_squared_error(y_true, y_pred)\n    RMSE = np.sqrt(MSE)\n    print(f\"MSE: {MSE}\\nRMSE: {RMSE}\")\n\n\n\n\nlinear_reg = make_pipeline(preprocessing, LinearRegression())\nlinear_reg.fit(X_train, y_train)\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('linearregression', LinearRegression())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('linearregression', LinearRegression())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')LinearRegressionLinearRegression()\n\n\n\ny_pred = linear_reg.predict(X_val)\n\n\nmetrics(y_val, y_pred)\n\nMAE: 4169.607569411409\nMSE: 36406996.983101465\nRMSE: 6033.821093063786\n\n\n\nscore = -cross_val_score(linear_reg, X_train, y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(score).describe()\n\ncount      10.000000\nmean     6223.816156\nstd       811.221206\nmin      5367.259534\n25%      5738.071105\n50%      5967.331953\n75%      6367.402518\nmax      7976.511184\ndtype: float64\n\n\n\n\n\n\nsvr_model = make_pipeline(preprocessing, SVR())\nsvr_model.fit(X_train, y_train)\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                ('svr', SVR())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                ('svr', SVR())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')SVRSVR()\n\n\n\ny_pred = svr_model.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 7814.88732173058\nMSE: 149910137.451377\nRMSE: 12243.77954111299\n\n\n\nparam_grid = {\n    \"svr__C\": [0.1, 1, 10, 100, 1000],\n    \"svr__gamma\": ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n    \"svr__kernel\": ['rbf', 'poly', 'sigmoid', 'linear'],\n    \"svr__epsilon\": [0.01, 0.1, 0.2, 0.5]\n}\n\nsvr_tuned = RandomizedSearchCV(svr_model, param_distributions=param_grid, n_iter=30, cv=3, scoring=\"neg_root_mean_squared_error\", random_state=42, n_jobs=-1, verbose=2)\n\nsvr_tuned.fit(X_train, y_train)\n\nFitting 3 folds for each of 30 candidates, totalling 90 fits\n\n\nRandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                                             ('svr', SVR())]),\n                   n_iter=30, n_jobs=-1,\n                   param_distributions={'svr__C': [0.1, 1, 10, 100, 1000],\n                                        'svr__epsilon': [0.01, 0.1, 0.2, 0.5],\n                                        'svr__gamma': ['scale', 'auto', 0.001,\n                                                       0.01, 0.1, 1],\n                                        'svr__kernel': ['rbf', 'poly',\n                                                        'sigmoid', 'linear']},\n                   random_state=42, scoring='neg_root_mean_squared_error',\n                   verbose=2)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                                             ('svr', SVR())]),\n                   n_iter=30, n_jobs=-1,\n                   param_distributions={'svr__C': [0.1, 1, 10, 100, 1000],\n                                        'svr__epsilon': [0.01, 0.1, 0.2, 0.5],\n                                        'svr__gamma': ['scale', 'auto', 0.001,\n                                                       0.01, 0.1, 1],\n                                        'svr__kernel': ['rbf', 'poly',\n                                                        'sigmoid', 'linear']},\n                   random_state=42, scoring='neg_root_mean_squared_error',\n                   verbose=2)estimator: PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                ('svr', SVR())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')SVRSVR()\n\n\n\n-svr_tuned.best_score_\n\n7645.012433741977\n\n\n\nsvr_tuned.best_params_\n\n{'svr__kernel': 'linear',\n 'svr__gamma': 0.01,\n 'svr__epsilon': 0.1,\n 'svr__C': 1000}\n\n\n\n\n\nUsing a simple DecisionTree as a baseline\n\ndt = make_pipeline(preprocessing, DecisionTreeRegressor(max_depth=3))\ndt.fit(X_train, y_train)\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('decisiontreeregressor', DecisionTreeRegressor(max_depth=3))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('decisiontreeregressor', DecisionTreeRegressor(max_depth=3))])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')DecisionTreeRegressorDecisionTreeRegressor(max_depth=3)\n\n\n\ny_pred = dt.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2777.9817164081323\nMSE: 20510058.067987088\nRMSE: 4528.803160658133\n\n\n\nscore = -cross_val_score(dt, X_train, y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(score).describe()\n\ncount      10.000000\nmean     4886.767496\nstd      1067.531833\nmin      3721.684778\n25%      4133.296988\n50%      4587.401285\n75%      5037.971872\nmax      6835.741056\ndtype: float64\n\n\n\nfeature_names = dt[\"columntransformer\"].get_feature_names_out()\n\n\n# Insights:\n# First splits on smoking -&gt;  confirming smoking dominates the cost signal\n# For the smokers, BMI is the next important factor\n# For non-smokers age is the next important factor\n\nplt.figure(figsize=(14, 10))\nplot_tree(\n    dt[\"decisiontreeregressor\"],\n     max_depth=4,\n     feature_names=feature_names,\n     filled=True,\n     rounded=True,\n     fontsize=10,\n     \n);\n\n\n\n\n\n\n\n\nUsing RandomizedSearch to find the best parameters for the Decisiontree\n\nparam_grid = {\n    \"decisiontreeregressor__max_depth\": range(2,20),\n    \"decisiontreeregressor__min_samples_split\": range(2,10),\n    \"decisiontreeregressor__min_samples_leaf\": range(1,10),\n    \"decisiontreeregressor__max_features\": [\"sqrt\", \"log2\", None]\n}\n\nrnd_decision_tree = RandomizedSearchCV(dt, param_distributions=param_grid, n_iter=100, scoring=\"neg_root_mean_squared_error\", random_state=42)\n\nrnd_decision_tree.fit(X_train, y_train)\n\nRandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequ...\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=3))]),\n                   n_iter=100,\n                   param_distributions={'decisiontreeregressor__max_depth': range(2, 20),\n                                        'decisiontreeregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'decisiontreeregressor__min_samples_leaf': range(1, 10),\n                                        'decisiontreeregressor__min_samples_split': range(2, 10)},\n                   random_state=42, scoring='neg_root_mean_squared_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequ...\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=3))]),\n                   n_iter=100,\n                   param_distributions={'decisiontreeregressor__max_depth': range(2, 20),\n                                        'decisiontreeregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'decisiontreeregressor__min_samples_leaf': range(1, 10),\n                                        'decisiontreeregressor__min_samples_split': range(2, 10)},\n                   random_state=42, scoring='neg_root_mean_squared_error')estimator: PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('decisiontreeregressor', DecisionTreeRegressor(max_depth=3))])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')DecisionTreeRegressorDecisionTreeRegressor(max_depth=3)\n\n\n\nrnd_decision_tree.best_params_\n\n{'decisiontreeregressor__min_samples_split': 4,\n 'decisiontreeregressor__min_samples_leaf': 9,\n 'decisiontreeregressor__max_features': None,\n 'decisiontreeregressor__max_depth': 4}\n\n\n\n-rnd_decision_tree.best_score_\n\n4816.461448818147\n\n\n\n# get a dataframe to show the training steps\n\nresults = pd.DataFrame(rnd_decision_tree.cv_results_)\n\n\nresults.head()\n\n\n\n\n\n\n\n\nmean_fit_time\nstd_fit_time\nmean_score_time\nstd_score_time\nparam_decisiontreeregressor__min_samples_split\nparam_decisiontreeregressor__min_samples_leaf\nparam_decisiontreeregressor__max_features\nparam_decisiontreeregressor__max_depth\nparams\nsplit0_test_score\nsplit1_test_score\nsplit2_test_score\nsplit3_test_score\nsplit4_test_score\nmean_test_score\nstd_test_score\nrank_test_score\n\n\n\n\n0\n0.008926\n0.001661\n0.004743\n0.002596\n2\n7\nNone\n19\n{'decisiontreeregressor__min_samples_split': 2...\n-6551.530702\n-4903.348250\n-4728.680073\n-5088.961025\n-4825.766404\n-5219.657291\n676.347302\n20\n\n\n1\n0.009064\n0.002511\n0.002820\n0.000438\n8\n2\nNone\n12\n{'decisiontreeregressor__min_samples_split': 8...\n-7242.564503\n-5128.548712\n-5189.496060\n-5399.390140\n-5370.049948\n-5666.009872\n795.000978\n33\n\n\n2\n0.005586\n0.000597\n0.002515\n0.000449\n7\n7\nsqrt\n13\n{'decisiontreeregressor__min_samples_split': 7...\n-7521.892916\n-5535.560296\n-10098.621144\n-5366.315712\n-4670.216493\n-6638.521312\n1972.911057\n57\n\n\n3\n0.007372\n0.000837\n0.002854\n0.000594\n5\n2\nNone\n13\n{'decisiontreeregressor__min_samples_split': 5...\n-7345.571759\n-5247.115430\n-5481.319187\n-5497.099554\n-5259.014318\n-5766.024049\n796.827865\n37\n\n\n4\n0.005022\n0.000546\n0.001917\n0.000193\n5\n4\nlog2\n3\n{'decisiontreeregressor__min_samples_split': 5...\n-10542.289822\n-5828.920153\n-7994.586393\n-10095.531506\n-7422.950625\n-8376.855700\n1743.042841\n97\n\n\n\n\n\n\n\n\ny_pred = rnd_decision_tree.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2562.7198812363467\nMSE: 18807488.914763357\nRMSE: 4336.76018644833\n\n\n\nModel error is reasonably low versus the data scale: MAE ≈ 2.6 k on mean charges ≈ 13.3 k (≈19 % relative), and RMSE 4.3 k is well below the dataset’s standard deviation (12.1 k), so the model captures most variance.\nBaseline check: always predicting the mean would give RMSE ≈ 12.1 k; your MSE of 18.8 M implies R² ≈ 0.87, meaning the tree explains roughly 87 % of the variation—strong for a single decision tree.\n\n\ndf[\"charges\"].describe()\n\ncount     1338.000000\nmean     13270.422265\nstd      12110.011237\nmin       1121.873900\n25%       4740.287150\n50%       9382.033000\n75%      16639.912515\nmax      63770.428010\nName: charges, dtype: float64\n\n\nPlot the best DecisionTree\n\nbest_tree = rnd_decision_tree.best_estimator_[\"decisiontreeregressor\"]\nbest_tree\n\nDecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=4)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.DecisionTreeRegressorDecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=4)\n\n\n\nplt.figure(figsize=(14, 10))\nplot_tree(\n     best_tree,\n     max_depth=4,\n     feature_names=feature_names,\n     filled=True,\n     rounded=True,\n     fontsize=10,\n     \n);\n\n\n\n\n\n\n\n\n\n\n\n\nrfr = make_pipeline(preprocessing, RandomForestRegressor())\nrfr.fit(X_train, y_train)\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])),\n                ('randomforestregressor', RandomForestRegressor())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])),\n                ('randomforestregressor', RandomForestRegressor())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')RandomForestRegressorRandomForestRegressor()\n\n\n\ny_pred = rfr.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2572.108498414695\nMSE: 22204912.574424837\nRMSE: 4712.208884846345\n\n\n\nscore = -cross_val_score(rfr, X_train, y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(score).describe()\n\ncount      10.000000\nmean     4999.162702\nstd       933.832049\nmin      4183.865103\n25%      4276.681296\n50%      4665.735171\n75%      5326.890498\nmax      6894.202512\ndtype: float64\n\n\n\n\nparam_grid = {\n    \"randomforestregressor__n_estimators\": range(50,200),\n    \"randomforestregressor__max_depth\": range(2,40),\n    \"randomforestregressor__min_samples_split\": range(2,10),\n    \"randomforestregressor__min_samples_leaf\": range(1,10),\n    \"randomforestregressor__max_features\": [\"sqrt\", \"log2\", None]\n}\n\nrnd_forest = RandomizedSearchCV(rfr, param_distributions=param_grid, n_iter=100, scoring=\"neg_root_mean_squared_error\", random_state=42)\n\nrnd_forest.fit(X_train, y_train)\n\nRandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequ...\n                   n_iter=100,\n                   param_distributions={'randomforestregressor__max_depth': range(2, 40),\n                                        'randomforestregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'randomforestregressor__min_samples_leaf': range(1, 10),\n                                        'randomforestregressor__min_samples_split': range(2, 10),\n                                        'randomforestregressor__n_estimators': range(50, 200)},\n                   random_state=42, scoring='neg_root_mean_squared_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequ...\n                   n_iter=100,\n                   param_distributions={'randomforestregressor__max_depth': range(2, 40),\n                                        'randomforestregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'randomforestregressor__min_samples_leaf': range(1, 10),\n                                        'randomforestregressor__min_samples_split': range(2, 10),\n                                        'randomforestregressor__n_estimators': range(50, 200)},\n                   random_state=42, scoring='neg_root_mean_squared_error')estimator: PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])),\n                ('randomforestregressor', RandomForestRegressor())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')RandomForestRegressorRandomForestRegressor()\n\n\n\nrnd_forest.best_params_\n\n{'randomforestregressor__n_estimators': 58,\n 'randomforestregressor__min_samples_split': 7,\n 'randomforestregressor__min_samples_leaf': 3,\n 'randomforestregressor__max_features': None,\n 'randomforestregressor__max_depth': 5}\n\n\n\n-rnd_forest.best_score_\n\n4704.255477078022\n\n\n\ny_pred = rnd_forest.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2481.440427770899\nMSE: 19115754.99090381\nRMSE: 4372.156789377962"
  },
  {
    "objectID": "posts/01_Medical_Costs_Regression/Regression_project.html#ensemble",
    "href": "posts/01_Medical_Costs_Regression/Regression_project.html#ensemble",
    "title": "Medical Costs - A Regression Task",
    "section": "",
    "text": "# Combine the best models\nensemble = VotingRegressor([\n    ('rf', make_pipeline(preprocessing, RandomForestRegressor(n_estimators=58, min_samples_split=7, min_samples_leaf=3, max_features=None, max_depth=5))),\n    ('dt', make_pipeline(preprocessing, DecisionTreeRegressor(min_samples_split=4, min_samples_leaf=9, max_features=None, max_depth=4))),\n    #('linear', make_pipeline(preprocessing, LinearRegression()))\n])\n\n\nensemble.fit(X_train, y_train)\n\nVotingRegressor(estimators=[('rf',\n                             Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequent')),\n                                                                                               ('onehot',\n                                                                                                OneHotEncoder(drop='if_binary'))]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=4,\n                                                                    min_samples_leaf=9,\n                                                                    min_samples_split=4))]))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.VotingRegressorVotingRegressor(estimators=[('rf',\n                             Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequent')),\n                                                                                               ('onehot',\n                                                                                                OneHotEncoder(drop='if_binary'))]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=4,\n                                                                    min_samples_leaf=9,\n                                                                    min_samples_split=4))]))])rfcolumntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')RandomForestRegressorRandomForestRegressor(max_depth=5, max_features=None, min_samples_leaf=3,\n                      min_samples_split=7, n_estimators=58)dtcolumntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')DecisionTreeRegressorDecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=4)\n\n\n\ny_pred = ensemble.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2480.1281238058236\nMSE: 18658891.89670748\nRMSE: 4319.59395044343\n\n\n\nscore = -cross_val_score(ensemble, X_train, y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(score).describe()\n\ncount      10.000000\nmean     4684.677748\nstd       975.940466\nmin      3759.443539\n25%      3969.849999\n50%      4450.199162\n75%      4785.729508\nmax      6575.824841\ndtype: float64"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I’m a passionate medical student with a growing fascination for machine learning and artificial intelligence. While studying medicine, I’ve discovered the incredible potential of ML to transform healthcare and data analysis.\n\n\n\nThis blog represents my commitment to learning in public—documenting my journey as I build hands-on projects and deepen my understanding of machine learning. Here’s what drives me:\n\nBridging domains: Exploring how ML can enhance medical research and clinical practice\nBuilding intuition: Working through real datasets to understand algorithms beyond theory\nSharing knowledge: Helping fellow learners see practical workflows and honest reflections\nContinuous growth: Documenting failures and successes as part of the learning process\n\n\n\n\nThis isn’t a tutorial site—it’s a documentation of my learning process. Each post represents a step in my understanding of machine learning, from data preprocessing to model evaluation and interpretation.\nCurrent Focus Areas: - Medical data analysis and prediction - Classical machine learning algorithms - Feature engineering and selection - Model interpretation and validation\n\n\n\nI focus on: - Practical projects with real-world datasets - Clear explanations of methods and reasoning - Visual storytelling through charts and analysis - Reproducible code that others can learn from - Honest documentation of challenges and insights\n\n\n\n\nClassical machine learning algorithms (regression, classification, clustering)\nMedical data analysis and prediction\nFeature engineering and model interpretation\nPython ecosystem (scikit-learn, pandas, matplotlib)\n\n\n\n\nI’d love to connect with fellow ML enthusiasts, especially those interested in healthcare applications:\n\nLinkedIn: My LinkedIn Profile\nGitHub: My GitHub Profile\n\n\nLearning in public • Building bridges between medicine and ML • Sharing the journey"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "I’d love to connect with fellow machine learning enthusiasts, especially those interested in healthcare applications and data science.\n\nLinkedIn: My LinkedIn Profile\nGitHub: My GitHub Profile\nEmail: patrick.linke@example.com\n\n\nAlways happy to chat about ML, medicine, and the intersection of both!"
  },
  {
    "objectID": "index.html#exploring-machine-learning-through-real-data",
    "href": "index.html#exploring-machine-learning-through-real-data",
    "title": "Intelligent Machines",
    "section": "",
    "text": "Welcome to my learning-in-public journal where I document my journey through applied machine learning. Here, you’ll find more information about this blog.\n\nLearning in public • Building understanding • Sharing insights"
  },
  {
    "objectID": "index.html#what-youll-find-here",
    "href": "index.html#what-youll-find-here",
    "title": "Intelligent Machines",
    "section": "",
    "text": "This isn’t a tutorial site—it’s a documentation of my learning process. Each post represents a step in my understanding of machine learning, from data preprocessing to model evaluation and interpretation.\nCurrent Focus Areas: - Medical data analysis and prediction - Classical machine learning algorithms - Feature engineering and selection - Model interpretation and validation\n\nLearning in public • Building understanding • Sharing insights"
  },
  {
    "objectID": "index.html#recent-posts",
    "href": "index.html#recent-posts",
    "title": "Intelligent Machines",
    "section": "",
    "text": "Check out my latest projects in the Blog section, where I share complete workflows, code, and insights from working with real datasets."
  },
  {
    "objectID": "about.html#medical-student-ml-enthusiast",
    "href": "about.html#medical-student-ml-enthusiast",
    "title": "About Me",
    "section": "",
    "text": "I’m a passionate medical student with a growing fascination for machine learning and artificial intelligence. While studying medicine, I’ve discovered the incredible potential of ML to transform healthcare and data analysis."
  },
  {
    "objectID": "about.html#why-this-blog-exists",
    "href": "about.html#why-this-blog-exists",
    "title": "About Me",
    "section": "Why This Blog Exists",
    "text": "Why This Blog Exists\nThis blog represents my commitment to learning in public—documenting my journey as I build hands-on projects and deepen my understanding of machine learning. Here’s what drives me:\n\nBridging domains: Exploring how machine learning can enhance medical research and clinical practice\nBuilding intuition: Working through real datasets to understand algorithms beyond theory\nSharing knowledge: Helping fellow learners see practical workflows and honest reflections\nContinuous growth: Documenting failures and successes as part of the learning process"
  },
  {
    "objectID": "about.html#my-approach",
    "href": "about.html#my-approach",
    "title": "About Me",
    "section": "My Approach",
    "text": "My Approach\nI focus on:\n\nPractical projects with real-world datasets\nClear explanations of methods and reasoning\nVisual storytelling through charts and analysis\nReproducible code that others can learn from\nHonest documentation of challenges and insights"
  },
  {
    "objectID": "about.html#current-learning-focus",
    "href": "about.html#current-learning-focus",
    "title": "About Me",
    "section": "",
    "text": "Classical machine learning algorithms (regression, classification, clustering)\nMedical data analysis and prediction\nFeature engineering and model interpretation\nPython ecosystem (scikit-learn, pandas, matplotlib)"
  },
  {
    "objectID": "about.html#lets-connect",
    "href": "about.html#lets-connect",
    "title": "About Me",
    "section": "Let’s Connect",
    "text": "Let’s Connect\nI’d love to connect with fellow machine learning enthusiasts, especially those interested in healthcare applications:\n\nLinkedIn: My LinkedIn Profile\nGitHub: My GitHub Profile\n\n\nLearning in public. Bridging medicine and machine learning. Sharing the journey one project at a time."
  },
  {
    "objectID": "contact.html#lets-connect",
    "href": "contact.html#lets-connect",
    "title": "Contact",
    "section": "Let’s Connect",
    "text": "Let’s Connect\nI’d love to connect with fellow machine learning enthusiasts, especially those interested in healthcare applications and data science.\n\nLinkedIn: My LinkedIn Profile\nGitHub: My GitHub Profile\n\n\nAlways happy to chat about ML, medicine, and the intersection of both!"
  },
  {
    "objectID": "contact.html#get-in-touch",
    "href": "contact.html#get-in-touch",
    "title": "Contact",
    "section": "",
    "text": "I’d love to connect with fellow machine learning enthusiasts, especially those interested in healthcare applications and data science.\n\nLinkedIn: My LinkedIn Profile\nGitHub: My GitHub Profile\nEmail: patrick.linke@example.com\n\n\nAlways happy to chat about ML, medicine, and the intersection of both!"
  },
  {
    "objectID": "contact.html#what-we-can-discuss",
    "href": "contact.html#what-we-can-discuss",
    "title": "Contact",
    "section": "",
    "text": "Machine learning projects and methodologies\nHealthcare data analysis\nLearning resources and study groups\nCollaboration opportunities\nQuestions about my blog posts\n\n\nAlways happy to chat about ML, medicine, and the intersection of both!"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/Regression_project.html",
    "href": "posts/02_Medical_Costs_Regression/Regression_project.html",
    "title": "Medical Costs - A Regression Task",
    "section": "",
    "text": "This notebook contains a regression project on the “Medical Cost Personal Datasets” dataset (url=https://www.kaggle.com/datasets/mirichoi0218/insurance)\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor, plot_tree\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.ensemble import VotingRegressor\n\n\ndf = pd.read_csv(\"../data/insurance.csv\")\n\n\ndf.head()\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n0\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.92400\n\n\n1\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.55230\n\n\n2\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.46200\n\n\n3\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.47061\n\n\n4\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.85520\n\n\n\n\n\n\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 7 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       1338 non-null   int64  \n 1   sex       1338 non-null   object \n 2   bmi       1338 non-null   float64\n 3   children  1338 non-null   int64  \n 4   smoker    1338 non-null   object \n 5   region    1338 non-null   object \n 6   charges   1338 non-null   float64\ndtypes: float64(2), int64(2), object(3)\nmemory usage: 73.3+ KB\n\n\n\n# check for missing values\n# -&gt; no missing values\ndf.isnull().sum()\n\nage         0\nsex         0\nbmi         0\nchildren    0\nsmoker      0\nregion      0\ncharges     0\ndtype: int64\n\n\n\naxes = df.hist(bins=50, density=True, figsize=(10,8), color=\"#0071E3\")\nfor ax in axes.ravel():\n    if ax is None:\n        continue\n    col = ax.get_title()\n    if col in df.select_dtypes(\"number\"):\n        df[col].plot(kind=\"kde\", ax=ax, color=\"#BF5AF2\", linewidth=2.6)\n    \n    ax.set_xlim(0)\n    ax.grid()\n    ax.set_facecolor(\"white\")\n\n    ax.set_title(\n        ax.get_title().capitalize(),\n        fontsize=16,\n        fontweight=\"semibold\",\n        color=\"#1D1D1F\",\n        pad=18,\n    )\n    \n\n\n\n\n\n\n\n\n\ndf[\"region\"].value_counts()\n\nregion\nsoutheast    364\nsouthwest    325\nnorthwest    325\nnortheast    324\nName: count, dtype: int64\n\n\n\ndf[\"sex\"].value_counts()\n\nsex\nmale      676\nfemale    662\nName: count, dtype: int64\n\n\n\ndf[\"smoker\"].value_counts()\n\nsmoker\nno     1064\nyes     274\nName: count, dtype: int64\n\n\n\n# Insights:\n# Charges generally rise with age\n# Three nearly parallel bands (different categories)\n# Smokers have higher charges than non-smokers\n\nsns.scatterplot(df, x=\"age\", y=\"charges\", alpha=0.5, hue=\"smoker\", palette=\"colorblind\")\nplt.legend(loc=[1.02,0.8])\n\n\n\n\n\n\n\n\n\n# Insights:\n# Charges generally rise with BMI\n# Smokers have higher charges than non-smokers\n\nsns.scatterplot(df, x=\"bmi\", y=\"charges\", alpha=0.5, hue=\"smoker\", palette=\"colorblind\") # higher BMI -&gt; higher charges\n\n\n\n\n\n\n\n\n\n# Insights:\n# Charges correlates to being a smoker and age quite strongly\n\ndf[\"smoker_flag\"] = df[\"smoker\"].map({\"yes\": 1, \"no\": 0})\ndf[\"sex_flag\"] = df[\"sex\"].map({\"female\": 0, \"male\": 1})\ndf.corr(numeric_only=True)[\"charges\"].sort_values(ascending=False)\n\ncharges        1.000000\nsmoker_flag    0.787251\nage            0.299008\nbmi            0.198341\nchildren       0.067998\nsex_flag       0.057292\nName: charges, dtype: float64\n\n\n\n\n\n\ndf = pd.read_csv(\"../data/insurance.csv\")\n\n\ndf.head()\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n0\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.92400\n\n\n1\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.55230\n\n\n2\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.46200\n\n\n3\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.47061\n\n\n4\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.85520\n\n\n\n\n\n\n\n\nnum_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"scaler\", StandardScaler())\n])\n\ncat_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"onehot\", OneHotEncoder(drop=\"if_binary\"))\n])\n\n\nfrom sklearn.compose import ColumnTransformer, make_column_selector\n\n\npreprocessing = ColumnTransformer([\n    (\"num\", num_pipeline, make_column_selector(dtype_include=np.number)),\n    (\"cat\", cat_pipeline, make_column_selector(dtype_include=object))\n])\n\n\n\n\nX = df.drop(\"charges\", axis=1)\n\n\ny = df[\"charges\"]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n\n\nprint(f\"X_train: {X_train.shape}; y_train: {y_train.shape}\\nX_val: {X_val.shape}; y_val: {y_val.shape}\\nX_test: {X_test.shape}; y_test: {y_test.shape}\")\n\nX_train: (795, 6); y_train: (795,)\nX_val: (342, 6); y_val: (342,)\nX_test: (201, 6); y_test: (201,)\n\n\n\n\n\n\n\ndef metrics(y_true, y_pred):\n    MAE = mean_absolute_error(y_true, y_pred)\n    print(f\"MAE: {MAE}\")\n\n    MSE = mean_squared_error(y_true, y_pred)\n    RMSE = np.sqrt(MSE)\n    print(f\"MSE: {MSE}\\nRMSE: {RMSE}\")\n\n\n\n\nlinear_reg = make_pipeline(preprocessing, LinearRegression())\nlinear_reg.fit(X_train, y_train)\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('linearregression', LinearRegression())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('linearregression', LinearRegression())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')LinearRegressionLinearRegression()\n\n\n\ny_pred = linear_reg.predict(X_val)\n\n\nmetrics(y_val, y_pred)\n\nMAE: 4169.607569411409\nMSE: 36406996.983101465\nRMSE: 6033.821093063786\n\n\n\nscore = -cross_val_score(linear_reg, X_train, y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(score).describe()\n\ncount      10.000000\nmean     6223.816156\nstd       811.221206\nmin      5367.259534\n25%      5738.071105\n50%      5967.331953\n75%      6367.402518\nmax      7976.511184\ndtype: float64\n\n\n\n\n\n\nsvr_model = make_pipeline(preprocessing, SVR())\nsvr_model.fit(X_train, y_train)\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                ('svr', SVR())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                ('svr', SVR())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')SVRSVR()\n\n\n\ny_pred = svr_model.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 7814.88732173058\nMSE: 149910137.451377\nRMSE: 12243.77954111299\n\n\n\nparam_grid = {\n    \"svr__C\": [0.1, 1, 10, 100, 1000],\n    \"svr__gamma\": ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n    \"svr__kernel\": ['rbf', 'poly', 'sigmoid', 'linear'],\n    \"svr__epsilon\": [0.01, 0.1, 0.2, 0.5]\n}\n\nsvr_tuned = RandomizedSearchCV(svr_model, param_distributions=param_grid, n_iter=30, cv=3, scoring=\"neg_root_mean_squared_error\", random_state=42, n_jobs=-1, verbose=2)\n\nsvr_tuned.fit(X_train, y_train)\n\nFitting 3 folds for each of 30 candidates, totalling 90 fits\n\n\nRandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                                             ('svr', SVR())]),\n                   n_iter=30, n_jobs=-1,\n                   param_distributions={'svr__C': [0.1, 1, 10, 100, 1000],\n                                        'svr__epsilon': [0.01, 0.1, 0.2, 0.5],\n                                        'svr__gamma': ['scale', 'auto', 0.001,\n                                                       0.01, 0.1, 1],\n                                        'svr__kernel': ['rbf', 'poly',\n                                                        'sigmoid', 'linear']},\n                   random_state=42, scoring='neg_root_mean_squared_error',\n                   verbose=2)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                                             ('svr', SVR())]),\n                   n_iter=30, n_jobs=-1,\n                   param_distributions={'svr__C': [0.1, 1, 10, 100, 1000],\n                                        'svr__epsilon': [0.01, 0.1, 0.2, 0.5],\n                                        'svr__gamma': ['scale', 'auto', 0.001,\n                                                       0.01, 0.1, 1],\n                                        'svr__kernel': ['rbf', 'poly',\n                                                        'sigmoid', 'linear']},\n                   random_state=42, scoring='neg_root_mean_squared_error',\n                   verbose=2)estimator: PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                ('svr', SVR())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')SVRSVR()\n\n\n\n-svr_tuned.best_score_\n\n7645.012433741977\n\n\n\nsvr_tuned.best_params_\n\n{'svr__kernel': 'linear',\n 'svr__gamma': 0.01,\n 'svr__epsilon': 0.1,\n 'svr__C': 1000}\n\n\n\n\n\nUsing a simple DecisionTree as a baseline\n\ndt = make_pipeline(preprocessing, DecisionTreeRegressor(max_depth=3))\ndt.fit(X_train, y_train)\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('decisiontreeregressor', DecisionTreeRegressor(max_depth=3))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('decisiontreeregressor', DecisionTreeRegressor(max_depth=3))])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')DecisionTreeRegressorDecisionTreeRegressor(max_depth=3)\n\n\n\ny_pred = dt.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2777.9817164081323\nMSE: 20510058.067987088\nRMSE: 4528.803160658133\n\n\n\nscore = -cross_val_score(dt, X_train, y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(score).describe()\n\ncount      10.000000\nmean     4886.767496\nstd      1067.531833\nmin      3721.684778\n25%      4133.296988\n50%      4587.401285\n75%      5037.971872\nmax      6835.741056\ndtype: float64\n\n\n\nfeature_names = dt[\"columntransformer\"].get_feature_names_out()\n\n\n# Insights:\n# First splits on smoking -&gt;  confirming smoking dominates the cost signal\n# For the smokers, BMI is the next important factor\n# For non-smokers age is the next important factor\n\nplt.figure(figsize=(14, 10))\nplot_tree(\n    dt[\"decisiontreeregressor\"],\n     max_depth=4,\n     feature_names=feature_names,\n     filled=True,\n     rounded=True,\n     fontsize=10,\n     \n);\n\n\n\n\n\n\n\n\nUsing RandomizedSearch to find the best parameters for the Decisiontree\n\nparam_grid = {\n    \"decisiontreeregressor__max_depth\": range(2,20),\n    \"decisiontreeregressor__min_samples_split\": range(2,10),\n    \"decisiontreeregressor__min_samples_leaf\": range(1,10),\n    \"decisiontreeregressor__max_features\": [\"sqrt\", \"log2\", None]\n}\n\nrnd_decision_tree = RandomizedSearchCV(dt, param_distributions=param_grid, n_iter=100, scoring=\"neg_root_mean_squared_error\", random_state=42)\n\nrnd_decision_tree.fit(X_train, y_train)\n\nRandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequ...\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=3))]),\n                   n_iter=100,\n                   param_distributions={'decisiontreeregressor__max_depth': range(2, 20),\n                                        'decisiontreeregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'decisiontreeregressor__min_samples_leaf': range(1, 10),\n                                        'decisiontreeregressor__min_samples_split': range(2, 10)},\n                   random_state=42, scoring='neg_root_mean_squared_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequ...\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=3))]),\n                   n_iter=100,\n                   param_distributions={'decisiontreeregressor__max_depth': range(2, 20),\n                                        'decisiontreeregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'decisiontreeregressor__min_samples_leaf': range(1, 10),\n                                        'decisiontreeregressor__min_samples_split': range(2, 10)},\n                   random_state=42, scoring='neg_root_mean_squared_error')estimator: PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('decisiontreeregressor', DecisionTreeRegressor(max_depth=3))])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')DecisionTreeRegressorDecisionTreeRegressor(max_depth=3)\n\n\n\nrnd_decision_tree.best_params_\n\n{'decisiontreeregressor__min_samples_split': 4,\n 'decisiontreeregressor__min_samples_leaf': 9,\n 'decisiontreeregressor__max_features': None,\n 'decisiontreeregressor__max_depth': 4}\n\n\n\n-rnd_decision_tree.best_score_\n\n4816.461448818147\n\n\n\n# get a dataframe to show the training steps\n\nresults = pd.DataFrame(rnd_decision_tree.cv_results_)\n\n\nresults.head()\n\n\n\n\n\n\n\n\nmean_fit_time\nstd_fit_time\nmean_score_time\nstd_score_time\nparam_decisiontreeregressor__min_samples_split\nparam_decisiontreeregressor__min_samples_leaf\nparam_decisiontreeregressor__max_features\nparam_decisiontreeregressor__max_depth\nparams\nsplit0_test_score\nsplit1_test_score\nsplit2_test_score\nsplit3_test_score\nsplit4_test_score\nmean_test_score\nstd_test_score\nrank_test_score\n\n\n\n\n0\n0.008926\n0.001661\n0.004743\n0.002596\n2\n7\nNone\n19\n{'decisiontreeregressor__min_samples_split': 2...\n-6551.530702\n-4903.348250\n-4728.680073\n-5088.961025\n-4825.766404\n-5219.657291\n676.347302\n20\n\n\n1\n0.009064\n0.002511\n0.002820\n0.000438\n8\n2\nNone\n12\n{'decisiontreeregressor__min_samples_split': 8...\n-7242.564503\n-5128.548712\n-5189.496060\n-5399.390140\n-5370.049948\n-5666.009872\n795.000978\n33\n\n\n2\n0.005586\n0.000597\n0.002515\n0.000449\n7\n7\nsqrt\n13\n{'decisiontreeregressor__min_samples_split': 7...\n-7521.892916\n-5535.560296\n-10098.621144\n-5366.315712\n-4670.216493\n-6638.521312\n1972.911057\n57\n\n\n3\n0.007372\n0.000837\n0.002854\n0.000594\n5\n2\nNone\n13\n{'decisiontreeregressor__min_samples_split': 5...\n-7345.571759\n-5247.115430\n-5481.319187\n-5497.099554\n-5259.014318\n-5766.024049\n796.827865\n37\n\n\n4\n0.005022\n0.000546\n0.001917\n0.000193\n5\n4\nlog2\n3\n{'decisiontreeregressor__min_samples_split': 5...\n-10542.289822\n-5828.920153\n-7994.586393\n-10095.531506\n-7422.950625\n-8376.855700\n1743.042841\n97\n\n\n\n\n\n\n\n\ny_pred = rnd_decision_tree.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2562.7198812363467\nMSE: 18807488.914763357\nRMSE: 4336.76018644833\n\n\n\nModel error is reasonably low versus the data scale: MAE ≈ 2.6 k on mean charges ≈ 13.3 k (≈19 % relative), and RMSE 4.3 k is well below the dataset’s standard deviation (12.1 k), so the model captures most variance.\nBaseline check: always predicting the mean would give RMSE ≈ 12.1 k; your MSE of 18.8 M implies R² ≈ 0.87, meaning the tree explains roughly 87 % of the variation—strong for a single decision tree.\n\n\ndf[\"charges\"].describe()\n\ncount     1338.000000\nmean     13270.422265\nstd      12110.011237\nmin       1121.873900\n25%       4740.287150\n50%       9382.033000\n75%      16639.912515\nmax      63770.428010\nName: charges, dtype: float64\n\n\nPlot the best DecisionTree\n\nbest_tree = rnd_decision_tree.best_estimator_[\"decisiontreeregressor\"]\nbest_tree\n\nDecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=4)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.DecisionTreeRegressorDecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=4)\n\n\n\nplt.figure(figsize=(14, 10))\nplot_tree(\n     best_tree,\n     max_depth=4,\n     feature_names=feature_names,\n     filled=True,\n     rounded=True,\n     fontsize=10,\n     \n);\n\n\n\n\n\n\n\n\n\n\n\n\nrfr = make_pipeline(preprocessing, RandomForestRegressor())\nrfr.fit(X_train, y_train)\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])),\n                ('randomforestregressor', RandomForestRegressor())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])),\n                ('randomforestregressor', RandomForestRegressor())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')RandomForestRegressorRandomForestRegressor()\n\n\n\ny_pred = rfr.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2572.108498414695\nMSE: 22204912.574424837\nRMSE: 4712.208884846345\n\n\n\nscore = -cross_val_score(rfr, X_train, y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(score).describe()\n\ncount      10.000000\nmean     4999.162702\nstd       933.832049\nmin      4183.865103\n25%      4276.681296\n50%      4665.735171\n75%      5326.890498\nmax      6894.202512\ndtype: float64\n\n\n\n\nparam_grid = {\n    \"randomforestregressor__n_estimators\": range(50,200),\n    \"randomforestregressor__max_depth\": range(2,40),\n    \"randomforestregressor__min_samples_split\": range(2,10),\n    \"randomforestregressor__min_samples_leaf\": range(1,10),\n    \"randomforestregressor__max_features\": [\"sqrt\", \"log2\", None]\n}\n\nrnd_forest = RandomizedSearchCV(rfr, param_distributions=param_grid, n_iter=100, scoring=\"neg_root_mean_squared_error\", random_state=42)\n\nrnd_forest.fit(X_train, y_train)\n\nRandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequ...\n                   n_iter=100,\n                   param_distributions={'randomforestregressor__max_depth': range(2, 40),\n                                        'randomforestregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'randomforestregressor__min_samples_leaf': range(1, 10),\n                                        'randomforestregressor__min_samples_split': range(2, 10),\n                                        'randomforestregressor__n_estimators': range(50, 200)},\n                   random_state=42, scoring='neg_root_mean_squared_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequ...\n                   n_iter=100,\n                   param_distributions={'randomforestregressor__max_depth': range(2, 40),\n                                        'randomforestregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'randomforestregressor__min_samples_leaf': range(1, 10),\n                                        'randomforestregressor__min_samples_split': range(2, 10),\n                                        'randomforestregressor__n_estimators': range(50, 200)},\n                   random_state=42, scoring='neg_root_mean_squared_error')estimator: PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])),\n                ('randomforestregressor', RandomForestRegressor())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')RandomForestRegressorRandomForestRegressor()\n\n\n\nrnd_forest.best_params_\n\n{'randomforestregressor__n_estimators': 58,\n 'randomforestregressor__min_samples_split': 7,\n 'randomforestregressor__min_samples_leaf': 3,\n 'randomforestregressor__max_features': None,\n 'randomforestregressor__max_depth': 5}\n\n\n\n-rnd_forest.best_score_\n\n4704.255477078022\n\n\n\ny_pred = rnd_forest.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2481.440427770899\nMSE: 19115754.99090381\nRMSE: 4372.156789377962\n\n\n\n\n\n\n\n# Combine the best models\nensemble = VotingRegressor([\n    ('rf', make_pipeline(preprocessing, RandomForestRegressor(n_estimators=58, min_samples_split=7, min_samples_leaf=3, max_features=None, max_depth=5))),\n    ('dt', make_pipeline(preprocessing, DecisionTreeRegressor(min_samples_split=4, min_samples_leaf=9, max_features=None, max_depth=4))),\n    #('linear', make_pipeline(preprocessing, LinearRegression()))\n])\n\n\nensemble.fit(X_train, y_train)\n\nVotingRegressor(estimators=[('rf',\n                             Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequent')),\n                                                                                               ('onehot',\n                                                                                                OneHotEncoder(drop='if_binary'))]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=4,\n                                                                    min_samples_leaf=9,\n                                                                    min_samples_split=4))]))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.VotingRegressorVotingRegressor(estimators=[('rf',\n                             Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequent')),\n                                                                                               ('onehot',\n                                                                                                OneHotEncoder(drop='if_binary'))]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=4,\n                                                                    min_samples_leaf=9,\n                                                                    min_samples_split=4))]))])rfcolumntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')RandomForestRegressorRandomForestRegressor(max_depth=5, max_features=None, min_samples_leaf=3,\n                      min_samples_split=7, n_estimators=58)dtcolumntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')DecisionTreeRegressorDecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=4)\n\n\n\ny_pred = ensemble.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2480.1281238058236\nMSE: 18658891.89670748\nRMSE: 4319.59395044343\n\n\n\nscore = -cross_val_score(ensemble, X_train, y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(score).describe()\n\ncount      10.000000\nmean     4684.677748\nstd       975.940466\nmin      3759.443539\n25%      3969.849999\n50%      4450.199162\n75%      4785.729508\nmax      6575.824841\ndtype: float64"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/Regression_project.html#eda",
    "href": "posts/02_Medical_Costs_Regression/Regression_project.html#eda",
    "title": "Medical Costs - A Regression Task",
    "section": "",
    "text": "df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 7 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       1338 non-null   int64  \n 1   sex       1338 non-null   object \n 2   bmi       1338 non-null   float64\n 3   children  1338 non-null   int64  \n 4   smoker    1338 non-null   object \n 5   region    1338 non-null   object \n 6   charges   1338 non-null   float64\ndtypes: float64(2), int64(2), object(3)\nmemory usage: 73.3+ KB\n\n\n\n# check for missing values\n# -&gt; no missing values\ndf.isnull().sum()\n\nage         0\nsex         0\nbmi         0\nchildren    0\nsmoker      0\nregion      0\ncharges     0\ndtype: int64\n\n\n\naxes = df.hist(bins=50, density=True, figsize=(10,8), color=\"#0071E3\")\nfor ax in axes.ravel():\n    if ax is None:\n        continue\n    col = ax.get_title()\n    if col in df.select_dtypes(\"number\"):\n        df[col].plot(kind=\"kde\", ax=ax, color=\"#BF5AF2\", linewidth=2.6)\n    \n    ax.set_xlim(0)\n    ax.grid()\n    ax.set_facecolor(\"white\")\n\n    ax.set_title(\n        ax.get_title().capitalize(),\n        fontsize=16,\n        fontweight=\"semibold\",\n        color=\"#1D1D1F\",\n        pad=18,\n    )\n    \n\n\n\n\n\n\n\n\n\ndf[\"region\"].value_counts()\n\nregion\nsoutheast    364\nsouthwest    325\nnorthwest    325\nnortheast    324\nName: count, dtype: int64\n\n\n\ndf[\"sex\"].value_counts()\n\nsex\nmale      676\nfemale    662\nName: count, dtype: int64\n\n\n\ndf[\"smoker\"].value_counts()\n\nsmoker\nno     1064\nyes     274\nName: count, dtype: int64\n\n\n\n# Insights:\n# Charges generally rise with age\n# Three nearly parallel bands (different categories)\n# Smokers have higher charges than non-smokers\n\nsns.scatterplot(df, x=\"age\", y=\"charges\", alpha=0.5, hue=\"smoker\", palette=\"colorblind\")\nplt.legend(loc=[1.02,0.8])\n\n\n\n\n\n\n\n\n\n# Insights:\n# Charges generally rise with BMI\n# Smokers have higher charges than non-smokers\n\nsns.scatterplot(df, x=\"bmi\", y=\"charges\", alpha=0.5, hue=\"smoker\", palette=\"colorblind\") # higher BMI -&gt; higher charges\n\n\n\n\n\n\n\n\n\n# Insights:\n# Charges correlates to being a smoker and age quite strongly\n\ndf[\"smoker_flag\"] = df[\"smoker\"].map({\"yes\": 1, \"no\": 0})\ndf[\"sex_flag\"] = df[\"sex\"].map({\"female\": 0, \"male\": 1})\ndf.corr(numeric_only=True)[\"charges\"].sort_values(ascending=False)\n\ncharges        1.000000\nsmoker_flag    0.787251\nage            0.299008\nbmi            0.198341\nchildren       0.067998\nsex_flag       0.057292\nName: charges, dtype: float64"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/Regression_project.html#preprocessing",
    "href": "posts/02_Medical_Costs_Regression/Regression_project.html#preprocessing",
    "title": "Medical Costs - A Regression Task",
    "section": "",
    "text": "df = pd.read_csv(\"../data/insurance.csv\")\n\n\ndf.head()\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n0\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.92400\n\n\n1\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.55230\n\n\n2\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.46200\n\n\n3\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.47061\n\n\n4\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.85520\n\n\n\n\n\n\n\n\nnum_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"scaler\", StandardScaler())\n])\n\ncat_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"onehot\", OneHotEncoder(drop=\"if_binary\"))\n])\n\n\nfrom sklearn.compose import ColumnTransformer, make_column_selector\n\n\npreprocessing = ColumnTransformer([\n    (\"num\", num_pipeline, make_column_selector(dtype_include=np.number)),\n    (\"cat\", cat_pipeline, make_column_selector(dtype_include=object))\n])\n\n\n\n\nX = df.drop(\"charges\", axis=1)\n\n\ny = df[\"charges\"]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n\n\nprint(f\"X_train: {X_train.shape}; y_train: {y_train.shape}\\nX_val: {X_val.shape}; y_val: {y_val.shape}\\nX_test: {X_test.shape}; y_test: {y_test.shape}\")\n\nX_train: (795, 6); y_train: (795,)\nX_val: (342, 6); y_val: (342,)\nX_test: (201, 6); y_test: (201,)"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/Regression_project.html#training-a-model",
    "href": "posts/02_Medical_Costs_Regression/Regression_project.html#training-a-model",
    "title": "Medical Costs - A Regression Task",
    "section": "",
    "text": "def metrics(y_true, y_pred):\n    MAE = mean_absolute_error(y_true, y_pred)\n    print(f\"MAE: {MAE}\")\n\n    MSE = mean_squared_error(y_true, y_pred)\n    RMSE = np.sqrt(MSE)\n    print(f\"MSE: {MSE}\\nRMSE: {RMSE}\")\n\n\n\n\nlinear_reg = make_pipeline(preprocessing, LinearRegression())\nlinear_reg.fit(X_train, y_train)\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('linearregression', LinearRegression())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('linearregression', LinearRegression())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')LinearRegressionLinearRegression()\n\n\n\ny_pred = linear_reg.predict(X_val)\n\n\nmetrics(y_val, y_pred)\n\nMAE: 4169.607569411409\nMSE: 36406996.983101465\nRMSE: 6033.821093063786\n\n\n\nscore = -cross_val_score(linear_reg, X_train, y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(score).describe()\n\ncount      10.000000\nmean     6223.816156\nstd       811.221206\nmin      5367.259534\n25%      5738.071105\n50%      5967.331953\n75%      6367.402518\nmax      7976.511184\ndtype: float64\n\n\n\n\n\n\nsvr_model = make_pipeline(preprocessing, SVR())\nsvr_model.fit(X_train, y_train)\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                ('svr', SVR())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                ('svr', SVR())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')SVRSVR()\n\n\n\ny_pred = svr_model.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 7814.88732173058\nMSE: 149910137.451377\nRMSE: 12243.77954111299\n\n\n\nparam_grid = {\n    \"svr__C\": [0.1, 1, 10, 100, 1000],\n    \"svr__gamma\": ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n    \"svr__kernel\": ['rbf', 'poly', 'sigmoid', 'linear'],\n    \"svr__epsilon\": [0.01, 0.1, 0.2, 0.5]\n}\n\nsvr_tuned = RandomizedSearchCV(svr_model, param_distributions=param_grid, n_iter=30, cv=3, scoring=\"neg_root_mean_squared_error\", random_state=42, n_jobs=-1, verbose=2)\n\nsvr_tuned.fit(X_train, y_train)\n\nFitting 3 folds for each of 30 candidates, totalling 90 fits\n\n\nRandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                                             ('svr', SVR())]),\n                   n_iter=30, n_jobs=-1,\n                   param_distributions={'svr__C': [0.1, 1, 10, 100, 1000],\n                                        'svr__epsilon': [0.01, 0.1, 0.2, 0.5],\n                                        'svr__gamma': ['scale', 'auto', 0.001,\n                                                       0.01, 0.1, 1],\n                                        'svr__kernel': ['rbf', 'poly',\n                                                        'sigmoid', 'linear']},\n                   random_state=42, scoring='neg_root_mean_squared_error',\n                   verbose=2)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                                             ('svr', SVR())]),\n                   n_iter=30, n_jobs=-1,\n                   param_distributions={'svr__C': [0.1, 1, 10, 100, 1000],\n                                        'svr__epsilon': [0.01, 0.1, 0.2, 0.5],\n                                        'svr__gamma': ['scale', 'auto', 0.001,\n                                                       0.01, 0.1, 1],\n                                        'svr__kernel': ['rbf', 'poly',\n                                                        'sigmoid', 'linear']},\n                   random_state=42, scoring='neg_root_mean_squared_error',\n                   verbose=2)estimator: PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                ('svr', SVR())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')SVRSVR()\n\n\n\n-svr_tuned.best_score_\n\n7645.012433741977\n\n\n\nsvr_tuned.best_params_\n\n{'svr__kernel': 'linear',\n 'svr__gamma': 0.01,\n 'svr__epsilon': 0.1,\n 'svr__C': 1000}\n\n\n\n\n\nUsing a simple DecisionTree as a baseline\n\ndt = make_pipeline(preprocessing, DecisionTreeRegressor(max_depth=3))\ndt.fit(X_train, y_train)\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('decisiontreeregressor', DecisionTreeRegressor(max_depth=3))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('decisiontreeregressor', DecisionTreeRegressor(max_depth=3))])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')DecisionTreeRegressorDecisionTreeRegressor(max_depth=3)\n\n\n\ny_pred = dt.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2777.9817164081323\nMSE: 20510058.067987088\nRMSE: 4528.803160658133\n\n\n\nscore = -cross_val_score(dt, X_train, y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(score).describe()\n\ncount      10.000000\nmean     4886.767496\nstd      1067.531833\nmin      3721.684778\n25%      4133.296988\n50%      4587.401285\n75%      5037.971872\nmax      6835.741056\ndtype: float64\n\n\n\nfeature_names = dt[\"columntransformer\"].get_feature_names_out()\n\n\n# Insights:\n# First splits on smoking -&gt;  confirming smoking dominates the cost signal\n# For the smokers, BMI is the next important factor\n# For non-smokers age is the next important factor\n\nplt.figure(figsize=(14, 10))\nplot_tree(\n    dt[\"decisiontreeregressor\"],\n     max_depth=4,\n     feature_names=feature_names,\n     filled=True,\n     rounded=True,\n     fontsize=10,\n     \n);\n\n\n\n\n\n\n\n\nUsing RandomizedSearch to find the best parameters for the Decisiontree\n\nparam_grid = {\n    \"decisiontreeregressor__max_depth\": range(2,20),\n    \"decisiontreeregressor__min_samples_split\": range(2,10),\n    \"decisiontreeregressor__min_samples_leaf\": range(1,10),\n    \"decisiontreeregressor__max_features\": [\"sqrt\", \"log2\", None]\n}\n\nrnd_decision_tree = RandomizedSearchCV(dt, param_distributions=param_grid, n_iter=100, scoring=\"neg_root_mean_squared_error\", random_state=42)\n\nrnd_decision_tree.fit(X_train, y_train)\n\nRandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequ...\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=3))]),\n                   n_iter=100,\n                   param_distributions={'decisiontreeregressor__max_depth': range(2, 20),\n                                        'decisiontreeregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'decisiontreeregressor__min_samples_leaf': range(1, 10),\n                                        'decisiontreeregressor__min_samples_split': range(2, 10)},\n                   random_state=42, scoring='neg_root_mean_squared_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequ...\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=3))]),\n                   n_iter=100,\n                   param_distributions={'decisiontreeregressor__max_depth': range(2, 20),\n                                        'decisiontreeregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'decisiontreeregressor__min_samples_leaf': range(1, 10),\n                                        'decisiontreeregressor__min_samples_split': range(2, 10)},\n                   random_state=42, scoring='neg_root_mean_squared_error')estimator: PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])),\n                ('decisiontreeregressor', DecisionTreeRegressor(max_depth=3))])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000253208039E0&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002531AED2540&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')DecisionTreeRegressorDecisionTreeRegressor(max_depth=3)\n\n\n\nrnd_decision_tree.best_params_\n\n{'decisiontreeregressor__min_samples_split': 4,\n 'decisiontreeregressor__min_samples_leaf': 9,\n 'decisiontreeregressor__max_features': None,\n 'decisiontreeregressor__max_depth': 4}\n\n\n\n-rnd_decision_tree.best_score_\n\n4816.461448818147\n\n\n\n# get a dataframe to show the training steps\n\nresults = pd.DataFrame(rnd_decision_tree.cv_results_)\n\n\nresults.head()\n\n\n\n\n\n\n\n\nmean_fit_time\nstd_fit_time\nmean_score_time\nstd_score_time\nparam_decisiontreeregressor__min_samples_split\nparam_decisiontreeregressor__min_samples_leaf\nparam_decisiontreeregressor__max_features\nparam_decisiontreeregressor__max_depth\nparams\nsplit0_test_score\nsplit1_test_score\nsplit2_test_score\nsplit3_test_score\nsplit4_test_score\nmean_test_score\nstd_test_score\nrank_test_score\n\n\n\n\n0\n0.008926\n0.001661\n0.004743\n0.002596\n2\n7\nNone\n19\n{'decisiontreeregressor__min_samples_split': 2...\n-6551.530702\n-4903.348250\n-4728.680073\n-5088.961025\n-4825.766404\n-5219.657291\n676.347302\n20\n\n\n1\n0.009064\n0.002511\n0.002820\n0.000438\n8\n2\nNone\n12\n{'decisiontreeregressor__min_samples_split': 8...\n-7242.564503\n-5128.548712\n-5189.496060\n-5399.390140\n-5370.049948\n-5666.009872\n795.000978\n33\n\n\n2\n0.005586\n0.000597\n0.002515\n0.000449\n7\n7\nsqrt\n13\n{'decisiontreeregressor__min_samples_split': 7...\n-7521.892916\n-5535.560296\n-10098.621144\n-5366.315712\n-4670.216493\n-6638.521312\n1972.911057\n57\n\n\n3\n0.007372\n0.000837\n0.002854\n0.000594\n5\n2\nNone\n13\n{'decisiontreeregressor__min_samples_split': 5...\n-7345.571759\n-5247.115430\n-5481.319187\n-5497.099554\n-5259.014318\n-5766.024049\n796.827865\n37\n\n\n4\n0.005022\n0.000546\n0.001917\n0.000193\n5\n4\nlog2\n3\n{'decisiontreeregressor__min_samples_split': 5...\n-10542.289822\n-5828.920153\n-7994.586393\n-10095.531506\n-7422.950625\n-8376.855700\n1743.042841\n97\n\n\n\n\n\n\n\n\ny_pred = rnd_decision_tree.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2562.7198812363467\nMSE: 18807488.914763357\nRMSE: 4336.76018644833\n\n\n\nModel error is reasonably low versus the data scale: MAE ≈ 2.6 k on mean charges ≈ 13.3 k (≈19 % relative), and RMSE 4.3 k is well below the dataset’s standard deviation (12.1 k), so the model captures most variance.\nBaseline check: always predicting the mean would give RMSE ≈ 12.1 k; your MSE of 18.8 M implies R² ≈ 0.87, meaning the tree explains roughly 87 % of the variation—strong for a single decision tree.\n\n\ndf[\"charges\"].describe()\n\ncount     1338.000000\nmean     13270.422265\nstd      12110.011237\nmin       1121.873900\n25%       4740.287150\n50%       9382.033000\n75%      16639.912515\nmax      63770.428010\nName: charges, dtype: float64\n\n\nPlot the best DecisionTree\n\nbest_tree = rnd_decision_tree.best_estimator_[\"decisiontreeregressor\"]\nbest_tree\n\nDecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=4)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.DecisionTreeRegressorDecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=4)\n\n\n\nplt.figure(figsize=(14, 10))\nplot_tree(\n     best_tree,\n     max_depth=4,\n     feature_names=feature_names,\n     filled=True,\n     rounded=True,\n     fontsize=10,\n     \n);\n\n\n\n\n\n\n\n\n\n\n\n\nrfr = make_pipeline(preprocessing, RandomForestRegressor())\nrfr.fit(X_train, y_train)\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])),\n                ('randomforestregressor', RandomForestRegressor())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])),\n                ('randomforestregressor', RandomForestRegressor())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')RandomForestRegressorRandomForestRegressor()\n\n\n\ny_pred = rfr.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2572.108498414695\nMSE: 22204912.574424837\nRMSE: 4712.208884846345\n\n\n\nscore = -cross_val_score(rfr, X_train, y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(score).describe()\n\ncount      10.000000\nmean     4999.162702\nstd       933.832049\nmin      4183.865103\n25%      4276.681296\n50%      4665.735171\n75%      5326.890498\nmax      6894.202512\ndtype: float64\n\n\n\n\nparam_grid = {\n    \"randomforestregressor__n_estimators\": range(50,200),\n    \"randomforestregressor__max_depth\": range(2,40),\n    \"randomforestregressor__min_samples_split\": range(2,10),\n    \"randomforestregressor__min_samples_leaf\": range(1,10),\n    \"randomforestregressor__max_features\": [\"sqrt\", \"log2\", None]\n}\n\nrnd_forest = RandomizedSearchCV(rfr, param_distributions=param_grid, n_iter=100, scoring=\"neg_root_mean_squared_error\", random_state=42)\n\nrnd_forest.fit(X_train, y_train)\n\nRandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequ...\n                   n_iter=100,\n                   param_distributions={'randomforestregressor__max_depth': range(2, 40),\n                                        'randomforestregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'randomforestregressor__min_samples_leaf': range(1, 10),\n                                        'randomforestregressor__min_samples_split': range(2, 10),\n                                        'randomforestregressor__n_estimators': range(50, 200)},\n                   random_state=42, scoring='neg_root_mean_squared_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequ...\n                   n_iter=100,\n                   param_distributions={'randomforestregressor__max_depth': range(2, 40),\n                                        'randomforestregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'randomforestregressor__min_samples_leaf': range(1, 10),\n                                        'randomforestregressor__min_samples_split': range(2, 10),\n                                        'randomforestregressor__n_estimators': range(50, 200)},\n                   random_state=42, scoring='neg_root_mean_squared_error')estimator: PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])),\n                ('randomforestregressor', RandomForestRegressor())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182BE8A1550&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000182B8278110&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')RandomForestRegressorRandomForestRegressor()\n\n\n\nrnd_forest.best_params_\n\n{'randomforestregressor__n_estimators': 58,\n 'randomforestregressor__min_samples_split': 7,\n 'randomforestregressor__min_samples_leaf': 3,\n 'randomforestregressor__max_features': None,\n 'randomforestregressor__max_depth': 5}\n\n\n\n-rnd_forest.best_score_\n\n4704.255477078022\n\n\n\ny_pred = rnd_forest.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2481.440427770899\nMSE: 19115754.99090381\nRMSE: 4372.156789377962"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/Regression_project.html#ensemble",
    "href": "posts/02_Medical_Costs_Regression/Regression_project.html#ensemble",
    "title": "Medical Costs - A Regression Task",
    "section": "",
    "text": "# Combine the best models\nensemble = VotingRegressor([\n    ('rf', make_pipeline(preprocessing, RandomForestRegressor(n_estimators=58, min_samples_split=7, min_samples_leaf=3, max_features=None, max_depth=5))),\n    ('dt', make_pipeline(preprocessing, DecisionTreeRegressor(min_samples_split=4, min_samples_leaf=9, max_features=None, max_depth=4))),\n    #('linear', make_pipeline(preprocessing, LinearRegression()))\n])\n\n\nensemble.fit(X_train, y_train)\n\nVotingRegressor(estimators=[('rf',\n                             Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequent')),\n                                                                                               ('onehot',\n                                                                                                OneHotEncoder(drop='if_binary'))]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=4,\n                                                                    min_samples_leaf=9,\n                                                                    min_samples_split=4))]))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.VotingRegressorVotingRegressor(estimators=[('rf',\n                             Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequent')),\n                                                                                               ('onehot',\n                                                                                                OneHotEncoder(drop='if_binary'))]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=4,\n                                                                    min_samples_leaf=9,\n                                                                    min_samples_split=4))]))])rfcolumntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')RandomForestRegressorRandomForestRegressor(max_depth=5, max_features=None, min_samples_leaf=3,\n                      min_samples_split=7, n_estimators=58)dtcolumntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')DecisionTreeRegressorDecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=4)\n\n\n\ny_pred = ensemble.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2480.1281238058236\nMSE: 18658891.89670748\nRMSE: 4319.59395044343\n\n\n\nscore = -cross_val_score(ensemble, X_train, y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(score).describe()\n\ncount      10.000000\nmean     4684.677748\nstd       975.940466\nmin      3759.443539\n25%      3969.849999\n50%      4450.199162\n75%      4785.729508\nmax      6575.824841\ndtype: float64"
  },
  {
    "objectID": "posts/01_Welcome/Hello_Blog.html",
    "href": "posts/01_Welcome/Hello_Blog.html",
    "title": "Hello Blog!",
    "section": "",
    "text": "Hello and Welcome to My Blog!\nI decided to start this blog to document my machine learning journey in public.\nI am fascinated by idea of building intelligent machines that can learn from data and help make better decisions - especially in fields where precision matters and the cost of errors is high.\nI’m a medical student, so the content will often feature medical topics. But beyond that, I’ll explore whatever I find interesting and intriguing at the moment and share what I learn along the way.\n\n\nJust Read Along\nNot everyone wants — or needs — to write code, and that’s perfectly fine.\nYou can still enjoy this blog by reading along, exploring the visuals, and following my explanations.\nThe goal is to make complex ideas intuitive, whether you’re coding beside me or just curious about how it all works.\n\n\nHow You Can Code Along\nIf you’d like to try the code yourself, you can download my notebooks and run the directly in Google Colab or on Kaggle — no installation required!\nOf course, you can also type along without downloading the notebooks.\nI highly encourage you to experiment with the code — this is one of the best learning experiences you’ll have!\nIf you get stuck or have any questions, feel free to reach out to my via the Contact page or ask an LLM :).\nIn general, ChatGPT, Claude, Gemnini, and similar models are great at explaining code, so feel free to use them to enhance your learning experience!\nThat said, there’s no pressure to code along. You can absolutely enjoy this blog by simply reading the posts, exploring the visuals, and following the explanations.\nEven without writing code, you’ll still get insights into how machine learning works in practice.\n\n\nProgramming Language and Libraries\nThe code will be written in Python, a programming language that’s been around since 1991.\nPython is great for data science, statistics, automation, machine learning and AI. It makes it easy to build prototypes and MVPs quickly. It is also fairly easy to learn, so I encourage you to check it out if any of the topics sound interesting.\nCore libraries I’ll use:\n\nNumpy — fundamental package for scientific computing\n\nPandas — data analysis and manipulation of tabular data\n\nMatplotlib.pyplot — plotting figures and creating visualizations\n\nSeaborn — advanced statistical plotting\nScikit-Learn — classical machine learning algorithms\n\n\n\nThanks for Reading This First Post!\nIf you’d like to know more about me and why I started this blog, check out the About page. Otherwise, dive into the next post and have fun!\nThis is just the beginning. Let’s see where curiosity — and a bit of code — takes us.\n\n\nCredits\nP.S. The image at the beginning of this post was inspired by @EdDonner’s fantastic course on AI Agents!\nWhile the style was inspired by the course, I created the final image myself using an AI model based on my own instructions."
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Intelligent Machines",
    "section": "",
    "text": "Hello Blog!"
  },
  {
    "objectID": "about.html#what-youll-find-here",
    "href": "about.html#what-youll-find-here",
    "title": "About Me",
    "section": "What You’ll Find Here",
    "text": "What You’ll Find Here\nThis isn’t a tutorial site — it’s a documentation of my learning process. Each post represents a step in my understanding of machine learning, from data preprocessing to model evaluation and interpretation.\nCurrent Focus Areas:\n\nMedical data analysis and prediction\nClassical machine learning algorithms\nFeature engineering and selection\nModel interpretation and validation"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "",
    "text": "Charges generally rise with age.\nSmokers consistently have higher and more variable charges than non-smokers.\n\n\n\n\nFig. 0 Showing the most important features identified by a Decision Tree Regressor.\n\n\n\n\n\n\n\n\n\n\n\nModels\nMAE\nMSE\nRMSE\nR2\n\n\n\n\n0\nLinearRegression\n4092.36\n31333268.50\n5597.61\n0.79\n\n\n1\nSVR\n3373.30\n37706594.68\n6140.57\n0.75\n\n\n2\nDecisionTreeRegressor\n2755.59\n21655894.86\n4653.59\n0.86\n\n\n3\nRandomForestRegressor\n2459.69\n18958974.55\n4354.19\n0.88\n\n\n\n\n\n\n\n\n\n\nPredicting medical costs isn’t just a math problem — it’s about understanding the real price of our health choices. For insurers, these predictions guide fairer pricing and risk assessment. For individuals, they reveal how habits like smoking or maintaining a healthy BMI can shape future expenses. In a world where healthcare costs can make or break financial stability, this kind of model helps turn data into smarter, more informed decisions.\n\n\n\nThe dataset comes from the Medical Cost Personal Dataset on Kaggle, containing 1,338 observations, each representing a single U.S. health insurance policyholder. Key features include age, sex, BMI, number of children, smoker status, and region. The target variable, charges, captures each person’s annual medical cost, ranging from about $1,000 to over $60,000. Despite its small size, the dataset offers rich insights into how lifestyle and demographics drive healthcare expenses.\n\n\n\nFig. 1 Shows the Distribution of Numeric Features in the Medical Costs Dataset\n\n\n\n\n\nFig. 2 Shows the Distribution of Categorical Features in the Medical Costs Dataset"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#tldr",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#tldr",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "",
    "text": "One-sentence summary of what you did and found. + key figures\n\nCharges generally rise with age\nCharges generally rise with BMI\nSmokers have higher charges than non-smokers"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#dataset",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#dataset",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "Dataset",
    "text": "Dataset\nHealth spending isn’t random—it reflects who we are and how we live. This project explores a classic insurance dataset that links people’s demographics and lifestyle to what they’re billed for medical care. Each row represents a policyholder, and the goal is to understand and predict individual medical charges from a handful of intuitive features.\nMedical Cost Personal Datasets Insurance Forecast by using Linear Regression\nThis is a tabular dataset of U.S. health insurance policyholders used to study how demographics and lifestyle relate to individual medical charges.\nThe dataset looks like this:\n\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n0\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.92400\n\n\n1\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.55230\n\n\n2\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.46200\n\n\n3\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.47061\n\n\n4\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.85520\n\n\n\n\n\n\n\n\n\n\n\n\nYou can check it out yourself on Kaggle!: “https://www.kaggle.com/datasets/mirichoi0218/insurance”"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#goal",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#goal",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "Goal",
    "text": "Goal\nPrimary goal: model or explain charges (continuous target) from features like age, BMI, smoking status, sex, and region.\n\nExploratory data analysis to understand drivers of healthcare spending.\nPredicting medical costs (regression) for pricing and risk assessment exercises.\nDemonstrating feature encoding, interaction effects, and model interpretability.\n\nCan we predict an individual’s medical costs based on demographic and lifestyle factors such as age, BMI, smoking status, and region?\nmaybe ask concrete questions here that i want to / will answer later with my analysis?!"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#methods",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#methods",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "Methods",
    "text": "Methods\nI’ll start with exploratory analysis—distributions, correlations, and feature effects—then build baseline models to quantify what matters most.\nI tried LinearRegression, SVR, DecisionTree, RandomForest and - combining my best models - a VotingRegressor"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#results",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#results",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "Results",
    "text": "Results\nMetrics, plots, confusion matrix, learning curve, etc."
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#what-i-learned",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#what-i-learned",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "6. What I Learned",
    "text": "6. What I Learned\nModel performance improved with complexity:\nTree-based models, especially Random Forest, captured the nonlinear impact of health and lifestyle factors most effectively. The findings align with real-world intuition — smokers and older individuals face substantially higher insurance costs."
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#links",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#links",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "Links",
    "text": "Links\n🔗 Full notebook on GitHub 🔗 Dataset on Kaggle"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#behind-the-scenes-my-code",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#behind-the-scenes-my-code",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "Behind The Scenes (My Code)",
    "text": "Behind The Scenes (My Code)"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#eda",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#eda",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "EDA",
    "text": "EDA\nChecking the structure of the DataFrame\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 7 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   age       1338 non-null   int64  \n 1   sex       1338 non-null   object \n 2   bmi       1338 non-null   float64\n 3   children  1338 non-null   int64  \n 4   smoker    1338 non-null   object \n 5   region    1338 non-null   object \n 6   charges   1338 non-null   float64\ndtypes: float64(2), int64(2), object(3)\nmemory usage: 73.3+ KB\n\n\nChecking for missing values\n\n# -&gt; no missing values\ndf.isnull().sum()\n\nage         0\nsex         0\nbmi         0\nchildren    0\nsmoker      0\nregion      0\ncharges     0\ndtype: int64\n\n\nCreating a new column with catrgorical BMI features\nBMI Categories\n\n\n\nBMI Category\nBMI Range\n\n\n\n\nUnderweight\nBelow 18.5\n\n\nHealthy\n18.5 – 24.9\n\n\nOverweight\n25.0 – 29.9\n\n\nObesity\n30.0 or above\n\n\n\n\nbins = [0, 18.5, 25, 30, float(\"inf\")]\nlabels = [\"underweight\", \"normal\", \"overweight\", \"obese\"]\n\ndf[\"BMI_category\"] = pd.cut(df[\"bmi\"], bins=bins, labels=labels, right=False)\n\nPlotting the distribution of the numeric columns\n\nnumeric_columns = ['age', 'bmi', 'children', 'charges']\n\nfig, axes = plt.subplots(2, 2, figsize=(12,10), sharey=False)\nfig.suptitle(\"Distribution of Numeric Features\", fontsize=18, weight=\"bold\")\n\nR, C = axes.shape\n\nfor k, (ax, col) in enumerate(zip(axes.flat, numeric_columns)):\n\n    j = k % C # 0 % 2 = 0; 1%2 = 1\n\n    sns.histplot(\n        data=df,\n        x=col,\n        bins=40,\n        ax=ax,\n        stat=\"density\",\n        color=\"#69b3a2\",\n        edgecolor=\"white\",\n        alpha=0.85,\n    )\n    sns.kdeplot(\n        data=df,\n        x=col,\n        ax=ax,\n        color=\"#b22222\",\n        linewidth=2.5,\n    )\n\n    #ax.set_title(col.capitalize(), fontsize=14, weight=\"semibold\")\n    ax.set_xlabel(col.capitalize(), weight=\"semibold\")\n    ax.set_ylabel(\"Density\" if j == 0 else \"\")\n    ax.set_xlim(left=0)\n    ax.tick_params(axis=\"both\", labelsize=12)\n\n    ax.set_facecolor(\"#f7f7f7\")\n\nfig.tight_layout(pad=1.5)\n\nsave_fig(\"numeric_dist_histplot\")\n\n\n\n\n\n\n\n\nPlotting the distribution of categorical columns\n\ncategorial_columns = ['sex', 'smoker', 'region', 'BMI_category']\n\nfig, axes = plt.subplots(2, 2, figsize=(10,8), sharey=False)\nfig.suptitle(\"Distribution of Categorical Features\", fontsize=18, weight=\"bold\")\n\nR, C = axes.shape\n\nfor k, (ax, col) in enumerate(zip(axes.flat, categorial_columns)):\n\n    j = k % C\n\n    sns.histplot(\n        data=df,\n        x=col,\n        bins=40,\n        ax=ax,\n        stat=\"count\",\n        color=\"#69b3a2\",\n        edgecolor=\"white\",\n        alpha=0.85,\n    )\n\n    ax.set_title(col.capitalize(), fontsize=14, weight=\"semibold\")\n    ax.set_xlabel(\"\")\n    ax.set_ylabel(\"Count\" if j == 0 else \"\")\n    ax.tick_params(axis=\"both\", labelsize=12)\n\n    ax.tick_params(axis=\"both\", labelsize=12)\n\n    ax.set_facecolor(\"#f7f7f7\")\n\nfig.tight_layout(pad=1.5)\n\nsave_fig(\"cat_dist_histplot\")\n\n\n\n\n\n\n\n\n\ndf[\"sex\"].value_counts()\n\nsex\nmale      676\nfemale    662\nName: count, dtype: int64\n\n\n\ndf[\"smoker\"].value_counts()\n\nsmoker\nno     1064\nyes     274\nName: count, dtype: int64\n\n\n\ndf[\"region\"].value_counts()\n\nregion\nsoutheast    364\nsouthwest    325\nnorthwest    325\nnortheast    324\nName: count, dtype: int64\n\n\n\ndf[\"BMI_category\"].value_counts()\n\nBMI_category\nobese          707\noverweight     386\nnormal         225\nunderweight     20\nName: count, dtype: int64\n\n\nTaking a look at the target variable\n\ndf[\"charges\"].describe()\n\ncount     1338.000000\nmean     13270.422265\nstd      12110.011237\nmin       1121.873900\n25%       4740.287150\n50%       9382.033000\n75%      16639.912515\nmax      63770.428010\nName: charges, dtype: float64\n\n\n\n# Insights:\n# Charges generally rise with age\n# Smokers have higher charges than non-smokers\n# Smokers not only have higher average charges, but their costs are much more spread out\n# non-smokers trend is smoother\n\nsns.scatterplot(df, x=\"age\", y=\"charges\", alpha=0.5, hue=\"smoker\")\nplt.title(\"Charges by Age\", fontsize=18, weight=\"bold\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Charges\")\nplt.legend(loc=\"best\", title=\"smoker\")\n\nax = plt.gca()\nax.set_facecolor(\"#f7f7f7\")\nplt.tight_layout()\n\nsave_fig(\"age_vs_charges\")\n\n\n\n\n\n\n\n\n\n# Insights\n# Charges increase with age across all BMI categories.\n# However, BMI category alone does not create clear separation in charges — there’s considerable overlap between normal, overweight, and obese groups.\n# The large vertical gaps between charge levels likely stem from other variables (e.g., smoking).\n# Overall, BMI has a smaller impact on charges than age or smoking status.\n\n\nplt.figure(figsize=(9,6))\nsns.scatterplot(df, x=\"age\", y=\"charges\", alpha=0.5, hue=\"BMI_category\")\nplt.title(\"Charges by Age\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Charges\")\nplt.legend(loc=[1.05, 0.3], title=\"BMI Category\")\n\nax = plt.gca()\nax.set_facecolor(\"#f7f7f7\")\n\nplt.tight_layout()\n\nsave_fig(\"age_vs_charges_bmi\")\n\n\n\n\n\n\n\n\n\n# Insights:\n# For somkers Charges generally rise with BMI\n# Smokers have higher charges than non-smokers\n# For non-smokers bmi has little effect\n\nsns.scatterplot(df, x=\"bmi\", y=\"charges\", alpha=0.5, hue=\"smoker\") # higher BMI -&gt; higher charges\nplt.title(\"Charges by BMI\", fontsize=18, weight=\"bold\")\nplt.xlabel(\"BMI\")\nplt.ylabel(\"Charges\")\n\nplt.legend(loc=\"best\", title=\"smoker\")\n\nax = plt.gca()\nax.set_facecolor(\"#f7f7f7\")\nplt.tight_layout()\n\nsave_fig(\"bmi_vs_charges\")\n\n\n\n\n\n\n\n\nCheck the correlation between Smoking and BMI on the charges\n\ndf[df.smoker==\"yes\"].charges.corr(df[df.smoker==\"yes\"].bmi)\n\n0.8064806070155408\n\n\n\ndf[df.smoker==\"no\"].charges.corr(df[df.smoker==\"no\"].bmi)\n\n0.08403654312833271\n\n\n\n# Insights:\n# Charges strongly correlate to being a smoker\n# Age and BMI follow respectively\n\ndf[\"smoker_flag\"] = df[\"smoker\"].map({\"yes\": 1, \"no\": 0})\ndf[\"sex_flag\"] = df[\"sex\"].map({\"female\": 0, \"male\": 1})\ndf.corr(numeric_only=True)[\"charges\"].sort_values(ascending=False)\n\ncharges        1.000000\nsmoker_flag    0.787251\nage            0.299008\nbmi            0.198341\nchildren       0.067998\nsex_flag       0.057292\nName: charges, dtype: float64"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#preprocessing",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#preprocessing",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "Preprocessing",
    "text": "Preprocessing\n\ndf = pd.read_csv(\"data/insurance.csv\")\n\n\ndf.head()\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n0\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.92400\n\n\n1\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.55230\n\n\n2\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.46200\n\n\n3\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.47061\n\n\n4\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.85520\n\n\n\n\n\n\n\n\nnum_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"scaler\", StandardScaler())\n])\n\ncat_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"onehot\", OneHotEncoder(drop=\"if_binary\"))\n])\n\n\nfrom sklearn.compose import ColumnTransformer, make_column_selector\n\n\npreprocessing = ColumnTransformer([\n    (\"num\", num_pipeline, make_column_selector(dtype_include=np.number)),\n    (\"cat\", cat_pipeline, make_column_selector(dtype_include=object))\n])\n\n\ntree_num_pipeline = Pipeline([\n   (\"imputer\", SimpleImputer(strategy=\"median\")) \n])\n\ntree_preprocessing = ColumnTransformer([\n    (\"num\", tree_num_pipeline, make_column_selector(dtype_include=np.number)),\n    (\"cat\", cat_pipeline, make_column_selector(dtype_include=object))\n])\n\n\nTrain Test Split\n\nX = df.drop(\"charges\", axis=1)\n\n\ny = df[\"charges\"]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n\n\nprint(f\"X_train: {X_train.shape}; y_train: {y_train.shape}\\nX_test: {X_test.shape}; y_test: {y_test.shape}\")\n\nX_train: (1137, 6); y_train: (1137,)\nX_test: (201, 6); y_test: (201,)"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#training-a-model",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#training-a-model",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "Training a Model",
    "text": "Training a Model\n\ndef metrics(y_true, y_pred):\n    MAE = mean_absolute_error(y_true, y_pred)\n    print(f\"MAE: {MAE}\")\n\n    MSE = mean_squared_error(y_true, y_pred)\n    RMSE = np.sqrt(MSE)\n    print(f\"MSE: {MSE}\\nRMSE: {RMSE}\")\n\n\nLinearRegression\n\nlinear_reg = make_pipeline(preprocessing, LinearRegression())\n\n\nlinear_reg_score = -cross_val_score(linear_reg, X_train, y_train, cv=5, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(linear_reg_score).describe()\n\ncount       5.000000\nmean     6173.951563\nstd       211.241338\nmin      5926.581771\n25%      6070.880265\n50%      6156.104487\n75%      6219.280117\nmax      6496.911172\ndtype: float64\n\n\n\n\nSVR\n\nsvr_model = make_pipeline(preprocessing, SVR())\n\n\nsvr_score = -cross_val_score(svr_model, X_train, y_train, cv=5, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(svr_score).describe()\n\ncount        5.000000\nmean     12595.037950\nstd       1099.948405\nmin      11392.920185\n25%      11770.593709\n50%      12616.341217\n75%      13004.470299\nmax      14190.864341\ndtype: float64\n\n\n\nparam_grid = {\n    \"svr__C\": [0.1, 1, 10, 1000],\n    \"svr__gamma\": ['scale', 'auto', 0.01, 0.1, 1],\n    \"svr__kernel\": ['rbf', 'linear'],\n    \"svr__epsilon\": [0.01, 0.1, 0.5]\n}\n\nsvr_tuned = RandomizedSearchCV(svr_model, param_distributions=param_grid, cv=3, n_iter= 100, scoring=\"neg_root_mean_squared_error\", random_state=42, n_jobs=-1, verbose=3)\n\nsvr_tuned.fit(X_train, y_train)\n\nFitting 3 folds for each of 100 candidates, totalling 300 fits\n\n\nRandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269773A09B0&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                                                OneHotEncoder(drop='if_binary'))]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269773A2780&gt;)])),\n                                             ('svr', SVR())]),\n                   n_iter=100, n_jobs=-1,\n                   param_distributions={'svr__C': [0.1, 1, 10, 1000],\n                                        'svr__epsilon': [0.01, 0.1, 0.5],\n                                        'svr__gamma': ['scale', 'auto', 0.01,\n                                                       0.1, 1],\n                                        'svr__kernel': ['rbf', 'linear']},\n                   random_state=42, scoring='neg_root_mean_squared_error',\n                   verbose=3)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269773A09B0&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                                                OneHotEncoder(drop='if_binary'))]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269773A2780&gt;)])),\n                                             ('svr', SVR())]),\n                   n_iter=100, n_jobs=-1,\n                   param_distributions={'svr__C': [0.1, 1, 10, 1000],\n                                        'svr__epsilon': [0.01, 0.1, 0.5],\n                                        'svr__gamma': ['scale', 'auto', 0.01,\n                                                       0.1, 1],\n                                        'svr__kernel': ['rbf', 'linear']},\n                   random_state=42, scoring='neg_root_mean_squared_error',\n                   verbose=3)estimator: PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269773A09B0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269773A2780&gt;)])),\n                ('svr', SVR())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269773A09B0&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269773A2780&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269773A09B0&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269773A2780&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')SVRSVR()\n\n\n\nsvr_score = -svr_tuned.best_score_\nsvr_score\n\n7333.541404442819\n\n\n\nsvr_tuned.best_params_\n\n{'svr__kernel': 'linear',\n 'svr__gamma': 'scale',\n 'svr__epsilon': 0.01,\n 'svr__C': 1000}\n\n\n\n\nDecisionTree\nUsing a simple DecisionTree as a baseline\n\ndt = make_pipeline(tree_preprocessing, DecisionTreeRegressor(max_depth=3))\ndt.fit(X_train, y_train)\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269760A4AD0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002696F9D7DA0&gt;)])),\n                ('decisiontreeregressor', DecisionTreeRegressor(max_depth=3))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269760A4AD0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002696F9D7DA0&gt;)])),\n                ('decisiontreeregressor', DecisionTreeRegressor(max_depth=3))])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269760A4AD0&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002696F9D7DA0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269760A4AD0&gt;SimpleImputerSimpleImputer(strategy='median')cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002696F9D7DA0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')DecisionTreeRegressorDecisionTreeRegressor(max_depth=3)\n\n\n\nbase_decision_tree_score = -cross_val_score(dt, X_train, y_train, cv=5, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(base_decision_tree_score).describe()\n\ncount       5.000000\nmean     4869.172374\nstd       295.376724\nmin      4446.480626\n25%      4768.196718\n50%      4829.922649\n75%      5142.062041\nmax      5159.199837\ndtype: float64\n\n\nUsing RandomizedSearch to find the best parameters for the Decisiontree\n\nparam_grid = {\n    \"decisiontreeregressor__max_depth\": range(2,20),\n    \"decisiontreeregressor__min_samples_split\": range(2,10),\n    \"decisiontreeregressor__min_samples_leaf\": range(1,10),\n    \"decisiontreeregressor__max_features\": [\"sqrt\", \"log2\", None]\n}\n\nrnd_decision_tree = RandomizedSearchCV(dt, param_distributions=param_grid, n_iter=100, cv=3, scoring=\"neg_root_mean_squared_error\", random_state=42)\n\nrnd_decision_tree.fit(X_train, y_train)\n\nRandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median'))]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269760A4AD0&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequent')),\n                                                                                               ('onehot',\n                                                                                                OneHot...\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=3))]),\n                   n_iter=100,\n                   param_distributions={'decisiontreeregressor__max_depth': range(2, 20),\n                                        'decisiontreeregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'decisiontreeregressor__min_samples_leaf': range(1, 10),\n                                        'decisiontreeregressor__min_samples_split': range(2, 10)},\n                   random_state=42, scoring='neg_root_mean_squared_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median'))]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269760A4AD0&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequent')),\n                                                                                               ('onehot',\n                                                                                                OneHot...\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=3))]),\n                   n_iter=100,\n                   param_distributions={'decisiontreeregressor__max_depth': range(2, 20),\n                                        'decisiontreeregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'decisiontreeregressor__min_samples_leaf': range(1, 10),\n                                        'decisiontreeregressor__min_samples_split': range(2, 10)},\n                   random_state=42, scoring='neg_root_mean_squared_error')estimator: PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269760A4AD0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002696F9D7DA0&gt;)])),\n                ('decisiontreeregressor', DecisionTreeRegressor(max_depth=3))])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269760A4AD0&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002696F9D7DA0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269760A4AD0&gt;SimpleImputerSimpleImputer(strategy='median')cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002696F9D7DA0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')DecisionTreeRegressorDecisionTreeRegressor(max_depth=3)\n\n\n\nrnd_decision_tree.best_params_\n\n{'decisiontreeregressor__min_samples_split': 4,\n 'decisiontreeregressor__min_samples_leaf': 9,\n 'decisiontreeregressor__max_features': None,\n 'decisiontreeregressor__max_depth': 4}\n\n\n\n-rnd_decision_tree.best_score_\n\n4770.267010134789\n\n\n\nrnd_decision_tree.best_estimator_\n\nPipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002694062E750&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000026976C13410&gt;)])),\n                ('decisiontreeregressor',\n                 DecisionTreeRegressor(max_depth=4, min_samples_leaf=9,\n                                       min_samples_split=4))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002694062E750&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000026976C13410&gt;)])),\n                ('decisiontreeregressor',\n                 DecisionTreeRegressor(max_depth=4, min_samples_leaf=9,\n                                       min_samples_split=4))])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002694062E750&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000026976C13410&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002694062E750&gt;SimpleImputerSimpleImputer(strategy='median')cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x0000026976C13410&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')DecisionTreeRegressorDecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=4)\n\n\n\ndecision_tree_score = -cross_val_score(rnd_decision_tree.best_estimator_, X_train, y_train, cv=5, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(decision_tree_score).describe()\n\ncount       5.000000\nmean     4752.431458\nstd       311.946236\nmin      4308.317556\n25%      4619.560739\n50%      4755.759409\n75%      4969.267050\nmax      5109.252536\ndtype: float64\n\n\n\nbest_tree = rnd_decision_tree.best_estimator_[\"decisiontreeregressor\"]\nbest_tree\n\nDecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=4)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.DecisionTreeRegressorDecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=4)\n\n\n\n# Insights:\n# First splits on smoking -&gt;  confirming smoking dominates the cost signal\n# For the smokers, BMI is the next important factor\n# For non-smokers age is the next important factor\n\n\nfeature_names = rnd_decision_tree.best_estimator_[\"columntransformer\"].get_feature_names_out()\npretty_names = [f.split(\"__\")[-1] for f in feature_names]\n\n\nfig, ax = plt.subplots(figsize=(11, 8), dpi=400)\n\nplot_tree(\n     best_tree,\n     max_depth=3,\n     feature_names=pretty_names,\n     filled=True,\n     rounded=True,\n     fontsize=10,\n     proportion=True, # show % of samples instead of counts\n     impurity=False, # hide squared_error\n     precision=1, # shorter numbers\n     ax=ax\n     \n)\n\nplt.title(\"Decision Tree\", fontsize=18, weight=\"bold\")\nplt.tight_layout()\n\nsave_fig(\"Decision_Tree_plot\", resolution=400)\n\n\n\n\n\n\n\n\nSmaller iamges for the Blog:\n\nfeature_names = rnd_decision_tree.best_estimator_[\"columntransformer\"].get_feature_names_out()\npretty_names = [f.split(\"__\")[-1] for f in feature_names]\n\n\nfig, ax = plt.subplots(figsize=(8, 6), dpi=300)\n\nplot_tree(\n     best_tree,\n     max_depth=2,\n     feature_names=pretty_names,\n     filled=True,\n     rounded=True,\n     fontsize=10,\n     proportion=True, # show % of samples instead of counts\n     impurity=False, # hide squared_error\n     precision=1, # shorter numbers\n     ax=ax\n     \n)\n\nplt.title(\"Decision Tree\", fontsize=18, weight=\"bold\")\nplt.tight_layout()\n\nsave_fig(\"Decision_Tree_plot_small\")\n\n\n\n\n\n\n\n\n\n\nRandomForestRegressor\n\nrfr = make_pipeline(tree_preprocessing, RandomForestRegressor())\n\n\nbase_random_forest_score = -cross_val_score(rfr, X_train, y_train, cv=5, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(base_random_forest_score).describe()\n\ncount       5.000000\nmean     4877.139833\nstd       293.198791\nmin      4441.898586\n25%      4733.486913\n50%      4949.047954\n75%      5123.462899\nmax      5137.802811\ndtype: float64\n\n\n\n\nparam_grid = {\n    \"randomforestregressor__n_estimators\": range(50,200),\n    \"randomforestregressor__max_depth\": range(2,40),\n    \"randomforestregressor__min_samples_split\": range(2,10),\n    \"randomforestregressor__min_samples_leaf\": range(1,10),\n    \"randomforestregressor__max_features\": [\"sqrt\", \"log2\", None]\n}\n\nrnd_forest = RandomizedSearchCV(rfr, param_distributions=param_grid, n_iter=100, scoring=\"neg_root_mean_squared_error\", random_state=42)\n\nrnd_forest.fit(X_train, y_train)\n\nRandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median'))]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269760A4AD0&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequent')),\n                                                                                               ('onehot',\n                                                                                                OneHotEncod...\n                   n_iter=100,\n                   param_distributions={'randomforestregressor__max_depth': range(2, 40),\n                                        'randomforestregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'randomforestregressor__min_samples_leaf': range(1, 10),\n                                        'randomforestregressor__min_samples_split': range(2, 10),\n                                        'randomforestregressor__n_estimators': range(50, 200)},\n                   random_state=42, scoring='neg_root_mean_squared_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomizedSearchCVRandomizedSearchCV(estimator=Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median'))]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269760A4AD0&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequent')),\n                                                                                               ('onehot',\n                                                                                                OneHotEncod...\n                   n_iter=100,\n                   param_distributions={'randomforestregressor__max_depth': range(2, 40),\n                                        'randomforestregressor__max_features': ['sqrt',\n                                                                                'log2',\n                                                                                None],\n                                        'randomforestregressor__min_samples_leaf': range(1, 10),\n                                        'randomforestregressor__min_samples_split': range(2, 10),\n                                        'randomforestregressor__n_estimators': range(50, 200)},\n                   random_state=42, scoring='neg_root_mean_squared_error')estimator: PipelinePipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='median'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269760A4AD0&gt;),\n                                                 ('cat',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(drop='if_binary'))]),\n                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002696F9D7DA0&gt;)])),\n                ('randomforestregressor', RandomForestRegressor())])columntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269760A4AD0&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002696F9D7DA0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x00000269760A4AD0&gt;SimpleImputerSimpleImputer(strategy='median')cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002696F9D7DA0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')RandomForestRegressorRandomForestRegressor()\n\n\n\nrnd_forest.best_params_\n\n{'randomforestregressor__n_estimators': 58,\n 'randomforestregressor__min_samples_split': 7,\n 'randomforestregressor__min_samples_leaf': 3,\n 'randomforestregressor__max_features': None,\n 'randomforestregressor__max_depth': 5}\n\n\n\n-rnd_forest.best_score_\n\n4621.142167648941\n\n\n\nrandom_forest_score = -cross_val_score(rnd_forest.best_estimator_, X_train, y_train, cv=5, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(random_forest_score).describe()\n\ncount       5.000000\nmean     4616.455082\nstd       359.807740\nmin      4048.132168\n25%      4533.837089\n50%      4709.176946\n75%      4786.871966\nmax      5004.257239\ndtype: float64\n\n\n\n\nComparing Models\n\n# Training all models on the full training set and then predicting on the test set\n\nmodels = [linear_reg, svr_tuned.best_estimator_, rnd_decision_tree.best_estimator_, rnd_forest.best_estimator_]\nmodel_names = [\"LinearRegression\", \"SVR\", \"DecisionTreeRegressor\", \"RandomForestRegressor\"]\n\nall_scores = {}\n\nfor name, model in zip(model_names, models):\n    model.fit(X_train, y_train)\n\n    y_pred = model.predict(X_test)\n\n    MAE = mean_absolute_error(y_test, y_pred)\n    MSE = mean_squared_error(y_test, y_pred)\n    RMSE = np.sqrt(MSE)\n    r2 = r2_score(y_test, y_pred)\n\n    all_scores[name] = {\"MAE\": round(MAE,2), \"MSE\": round(MSE,2), \"RMSE\": round(RMSE,2), \"R2\": round(r2,2)}\n\ndf_model_comparison = pd.DataFrame(all_scores).T\n\n\ndf_model_comparison.index.name = \"Models\"\n\n\ndf_model_comparison\n\n\n\n\n\n\n\n\nMAE\nMSE\nRMSE\nR2\n\n\nModels\n\n\n\n\n\n\n\n\nLinearRegression\n4092.36\n31333268.50\n5597.61\n0.79\n\n\nSVR\n3373.30\n37706594.68\n6140.57\n0.75\n\n\nDecisionTreeRegressor\n2755.59\n21655894.86\n4653.59\n0.86\n\n\nRandomForestRegressor\n2459.69\n18958974.55\n4354.19\n0.88\n\n\n\n\n\n\n\n\ndf_model_comparison.to_csv(\"data/model_comparison_metrics.csv\")\n\n\n# comparing RMSE across all models\n\nplt.figure(figsize=(10,7))\nsns.barplot(data=df_model_comparison, x=\"Models\", y=\"RMSE\")\nplt.title(\"Model Comparison: RMSE\", fontsize=18, weight=\"bold\")\nplt.xlabel(\"Model\")\nplt.ylabel(\"RMSE\")\n#plt.ylim(0,1)\n\nplt.tight_layout()\n\nsave_fig(\"RMSE_score\")\n\n\n\n\n\n\n\n\n\n# Normalize so that lowest RMSE → 1, highest → 0\nrmse_norm = 1 - (df_model_comparison[\"RMSE\"] - df_model_comparison[\"RMSE\"].min()) / (df_model_comparison[\"RMSE\"].max() - df_model_comparison[\"RMSE\"].min())\n\n\nrmse_norm\n\nModels\nLinearRegression         0.303944\nSVR                      0.000000\nDecisionTreeRegressor    0.832398\nRandomForestRegressor    1.000000\nName: RMSE, dtype: float64\n\n\n\n# comparing RMSE across all models\n\nplt.figure(figsize=(10,7))\nsns.barplot(data=df_model_comparison, x=\"Models\", y=rmse_norm)\nplt.title(\"Model Comparison: Normalized RMSE\", fontsize=18, weight=\"bold\")\nplt.xlabel(\"Model\")\nplt.ylabel(\"Normalized RMSE Score\")\n#plt.ylim(0,1)\n\nplt.tight_layout()\n\nsave_fig(\"RMSE_score_norm\")\n\n\n\n\n\n\n\n\n\n# comparing R2 score across all models\n\nplt.figure(figsize=(10,7))\nsns.barplot(data=df_model_comparison, x=\"Models\", y=\"R2\")\nplt.title(\"Model Comparison: R² Score\", fontsize=18, weight=\"bold\")\nplt.xlabel(\"Model\")\nplt.ylabel(\"R2\")\nplt.ylim(0,1)\n\nplt.tight_layout()\n\nsave_fig(\"R2_score\")"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#ensemble",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#ensemble",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "Ensemble",
    "text": "Ensemble\n\n# Combine the best models\nensemble = VotingRegressor([\n    ('rf', make_pipeline(preprocessing, RandomForestRegressor(n_estimators=58, min_samples_split=7, min_samples_leaf=3, max_features=None, max_depth=5))),\n    ('dt', make_pipeline(preprocessing, DecisionTreeRegressor(min_samples_split=4, min_samples_leaf=9, max_features=None, max_depth=4))),\n    #('linear', make_pipeline(preprocessing, LinearRegression()))\n])\n\n\nensemble.fit(X_train, y_train)\n\nVotingRegressor(estimators=[('rf',\n                             Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequent')),\n                                                                                               ('onehot',\n                                                                                                OneHotEncoder(drop='if_binary'))]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=4,\n                                                                    min_samples_leaf=9,\n                                                                    min_samples_split=4))]))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.VotingRegressorVotingRegressor(estimators=[('rf',\n                             Pipeline(steps=[('columntransformer',\n                                              ColumnTransformer(transformers=[('num',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='median')),\n                                                                                               ('scaler',\n                                                                                                StandardScaler())]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_...\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                                                              ('cat',\n                                                                               Pipeline(steps=[('imputer',\n                                                                                                SimpleImputer(strategy='most_frequent')),\n                                                                                               ('onehot',\n                                                                                                OneHotEncoder(drop='if_binary'))]),\n                                                                               &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])),\n                                             ('decisiontreeregressor',\n                                              DecisionTreeRegressor(max_depth=4,\n                                                                    min_samples_leaf=9,\n                                                                    min_samples_split=4))]))])rfcolumntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')RandomForestRegressorRandomForestRegressor(max_depth=5, max_features=None, min_samples_leaf=3,\n                      min_samples_split=7, n_estimators=58)dtcolumntransformer: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(drop='if_binary'))]),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;)])num&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E731C55F10&gt;SimpleImputerSimpleImputer(strategy='median')StandardScalerStandardScaler()cat&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000001E760EDBEF0&gt;SimpleImputerSimpleImputer(strategy='most_frequent')OneHotEncoderOneHotEncoder(drop='if_binary')DecisionTreeRegressorDecisionTreeRegressor(max_depth=4, min_samples_leaf=9, min_samples_split=4)\n\n\n\ny_pred = ensemble.predict(X_val)\nmetrics(y_val, y_pred)\n\nMAE: 2480.1281238058236\nMSE: 18658891.89670748\nRMSE: 4319.59395044343\n\n\n\nscore = -cross_val_score(ensemble, X_train, y_train, cv=10, scoring=\"neg_root_mean_squared_error\")\n\n\npd.Series(score).describe()\n\ncount      10.000000\nmean     4684.677748\nstd       975.940466\nmin      3759.443539\n25%      3969.849999\n50%      4450.199162\n75%      4785.729508\nmax      6575.824841\ndtype: float64\n\n\n\nEvaluate the Model on the Test set\n\ndf[\"charges\"].describe()\n\ncount     1338.000000\nmean     13270.422265\nstd      12110.011237\nmin       1121.873900\n25%       4740.287150\n50%       9382.033000\n75%      16639.912515\nmax      63770.428010\nName: charges, dtype: float64"
  },
  {
    "objectID": "about.html#who-am-i",
    "href": "about.html#who-am-i",
    "title": "About Me",
    "section": "Who am I?",
    "text": "Who am I?\nHi, I’m Patrick — a medical student fascinated by how machine learning and artificial intelligence are reshaping healthcare.\nThis blog is where I document my journey — learning, experimenting, and sharing insights as I explore how data and algorithms can improve decision-making."
  },
  {
    "objectID": "about.html#start-here",
    "href": "about.html#start-here",
    "title": "About Me",
    "section": "Start Here",
    "text": "Start Here\nYou can start here or explore the Blog! Have fun!"
  },
  {
    "objectID": "posts/01_Welcome/Hello_Blog.html#just-read-along",
    "href": "posts/01_Welcome/Hello_Blog.html#just-read-along",
    "title": "Hello Blog!",
    "section": "Just Read Along",
    "text": "Just Read Along\nNot everyone wants — or needs — to write code, and that’s perfectly fine.\nYou can still enjoy this blog by reading along, exploring the visuals, and following my explanations.\nThe goal is to make complex ideas intuitive, whether you’re coding beside me or just curious about how it all works."
  },
  {
    "objectID": "home.html",
    "href": "home.html",
    "title": "Intelligent Machines",
    "section": "",
    "text": "Getting Started\n\n\n\nCheck out my latest projects in the Blog section, where I share complete workflows, code, and insights from working with real datasets.\n\n\n\nWelcome to my learning-in-public journal where I document my journey through applied machine learning. Here, you’ll find more information about this blog.\n\nLearning in public • Building understanding • Sharing insights"
  },
  {
    "objectID": "home.html#recent-posts",
    "href": "home.html#recent-posts",
    "title": "Intelligent Machines",
    "section": "",
    "text": "Check out my latest projects in the Blog section, where I share complete workflows, code, and insights from working with real datasets."
  },
  {
    "objectID": "home.html#exploring-machine-learning-through-real-data",
    "href": "home.html#exploring-machine-learning-through-real-data",
    "title": "Intelligent Machines",
    "section": "",
    "text": "Welcome to my learning-in-public journal where I document my journey through applied machine learning. Here, you’ll find more information about this blog.\n\nLearning in public • Building understanding • Sharing insights"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#understanding-the-problem",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#understanding-the-problem",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "Understanding the Problem",
    "text": "Understanding the Problem\nAfter seeing how clearly the data separated people into different cost groups, I wanted to step back and define the problem more clearly. What exactly are we trying to predict—and why does it matter?\nIn this project, the goal is to predict medical insurance charges, the total annual billing amount for individual policyholders. The dataset includes 1,338 records, each representing a person with attributes that seem simple on the surface yet reveal deep complexity when combined: age, body mass index (BMI), number of children, smoking status, sex, and region. The target variable, charges, captures the yearly medical cost in U.S. dollars.\nThis prediction task isn’t just a mathematical exercise—it sits at the intersection of economics, health, and human behavior. Accurate estimates of medical costs can support multiple perspectives:\n\nFor insurers: better risk assessment and fairer premium pricing\nFor policymakers: a clearer picture of which lifestyle and demographic factors drive national healthcare spending\nFor individuals: a tangible reminder of how choices—like smoking or maintaining a healthy BMI—can translate into real financial impact\n\nIn other words, predicting medical costs isn’t only about numbers—it’s about connecting data to the everyday realities of health and money."
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#the-data-were-working-with",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#the-data-were-working-with",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "The Data We’re Working With",
    "text": "The Data We’re Working With\nThe dataset I used is the Medical Cost Personal Dataset, a publicly available collection of U.S. health insurance records originally designed for exploring regression modeling.\nEach record represents one policyholder, described by a handful of demographic and lifestyle attributes:\n\nage: Age of the individual\nsex: Biological sex\nbmi: Body mass index, a proxy for body fat based on height and weight\nchildren: Number of dependents covered under the insurance plan\nsmoker: Whether the person is a smoker\nregion: The U.S. region of residence (northeast, northwest, southeast, southwest)\n\nThe target variable, charges, represents each person’s annual medical insurance cost—ranging from just over $1,000 to more than $60,000. That wide spread hints at strong underlying patterns and disparities in health risk. For instance, two people of similar age might have dramatically different costs depending on smoking status or BMI.\nIt’s a compact dataset—only 1,338 rows—but it packs enough variation to uncover meaningful relationships between health behavior and financial risk. In that sense, it’s a perfect sandbox for exploring how data can translate human complexity into predictive insight.\n(You can explore the dataset yourself on Kaggle here.)"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#key-result",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#key-result",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "",
    "text": "Charges generally rise with age\nSmokers consistently have higher and more variable charges than non-smokers.\nCharges tend to rise with BMI, mainly among smokers (little effect for non-smokers).\n\n\n\n\nFig. 0 Showing the most important features identified by a Decision Tree Regressor.\n\n\n\n\n\n\n\n\n\n\n\nModels\nMAE\nMSE\nRMSE\nR2\n\n\n\n\n0\nLinearRegression\n4092.36\n31333268.50\n5597.61\n0.79\n\n\n1\nSVR\n3373.30\n37706594.68\n6140.57\n0.75\n\n\n2\nDecisionTreeRegressor\n2755.59\n21655894.86\n4653.59\n0.86\n\n\n3\nRandomForestRegressor\n2459.69\n18958974.55\n4354.19\n0.88"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#why-it-matters",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#why-it-matters",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "2. Why It Matters",
    "text": "2. Why It Matters\nPredicting medical costs isn’t just a math problem — it’s about understanding the real price of our health choices. For insurers, these predictions guide fairer pricing and risk assessment. For individuals, they reveal how habits like smoking or maintaining a healthy BMI can shape future expenses. In a world where healthcare costs can make or break financial stability, this kind of model helps turn data into smarter, more informed decisions."
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#the-data",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#the-data",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "3. The Data",
    "text": "3. The Data\nThe dataset comes from the Medical Cost Personal Dataset on Kaggle, containing 1,338 observations, each representing a single U.S. health insurance policyholder. Key features include age, sex, BMI, number of children, smoker status, and region. The target variable, charges, captures each person’s annual medical cost, ranging from about $1,000 to over $60,000. Despite its small size, the dataset offers rich insights into how lifestyle and demographics drive healthcare expenses.\n\n\n\nFig. 1 Shows the Distribution of Numeric Features in the Medical Costs Dataset\n\n\n\n\n\nFig. 2 Shows the Distribution of Categorical Features in the Medical Costs Dataset"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#what-i-did",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#what-i-did",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "4. What I Did",
    "text": "4. What I Did\nExplored the medical cost dataset with visuals — distributions, correlations, and feature effects — to link age, BMI, and smoking to charges. Cleaned numeric features with StandardScaler and categorical variables with OneHotEncoder. Trained LinearRegression, SVR, DecisionTreeRegressor, and RandomForestRegressor, tuning hyperparameters with RandomizedSearchCV. Evaluated MAE, MSE, RMSE, and R² on the test set and compared models visually."
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#what-i-found",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#what-i-found",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "5. What I Found",
    "text": "5. What I Found\nInsurance charges tend to increase with age. Smokers have significantly higher and more variable charges compared to non-smokers, whose costs show a smoother, more consistent trend.\nAmong smokers, insurance charges generally increase with higher BMI, while BMI has little impact on costs for non-smokers. Within non-smokers, age drives costs.\nFeature importance analysis (from the tree-based models) highlighted smoking, age, and BMI as the top predictors — confirming both domain expectations and model consistency.\nThe Random Forest Regressor achieved the best results, with the lowest RMSE (≈ 4354) and highest R² (≈ 0.88), indicating strong predictive accuracy and generalization on unseen data, showing that it is possible to predict medical costs based on key personal and lifestyle factors. This demonstrates that data-driven models can effectively capture the underlying relationships between health behaviors and medical expenses, enabling more accurate cost forecasting and better-informed healthcare and policy decisions.\n\n\n\nFig. 3 Charges increase with age, and smokers have significantly higher and more variable charges than non-smokers.\n\n\n\n\n\nFig. 4 Smokers consistently have higher charges than non-smokers. Among smokers, charges increase strongly with BMI (r ≈ 0.81), while among non-smokers, BMI has almost no relationship with charges (r ≈ 0.08). This indicates a strong interaction effect — smoking amplifies the impact of BMI on charges.\n\n\n\n\n\nFig. 5 Decision tree regression model predicting medical insurance charges. The model splits data points into groups based on key factors. The most important splitting criterion is smoking status. Among non-smokers, age is the most influential variable, while for smokers, BMI plays the dominant role. The “value” shown in each node represents the model’s predicted target value (here, the estimated insurance cost in dollars).\n\n\n\n\n\nFig. 6 Comparison of Root Mean Squared Error (RMSE) values for different regression models on the test set. The RMSE measures the average magnitude of prediction errors, with lower values indicating better model performance. The Random Forest Regressor achieved the lowest RMSE, followed by the Decision Tree Regressor, while the SVR and Linear Regression models showed higher error levels, suggesting less accurate predictions.)\n\n\n\n\n\nFig. 7 Comparison of R² scores for different regression models on the test set. The R² score represents the proportion of variance in medical insurance charges explained by each model. Higher values indicate better predictive performance. The Random Forest Regressor achieved the highest R², followed closely by the Decision Tree Regressor, while Linear Regression and SVR showed comparatively lower explanatory power."
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#whats-next",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#whats-next",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "7. What’s Next",
    "text": "7. What’s Next\nThis project shows that predicting medical costs is possible — but there’s room to grow. Future work could explore more advanced models like Gradient Boosting or XGBoost to see if they capture even subtler patterns in the data. Another direction is adding richer features to improve model depth and realism. Finally, scaling this work to larger, more diverse datasets would help assess how well these findings hold up across different populations. The next steps are open — it’s up to you to take this foundation and push it further."
  },
  {
    "objectID": "posts/00_Example_structure/example.html",
    "href": "posts/00_Example_structure/example.html",
    "title": "Project Title",
    "section": "",
    "text": "PREVIEW IMAGE"
  },
  {
    "objectID": "posts/00_Example_structure/example.html#hook-key-result",
    "href": "posts/00_Example_structure/example.html#hook-key-result",
    "title": "Project Title",
    "section": "1. Hook / Key Result",
    "text": "1. Hook / Key Result\nStart strong — what did you discover or prove?\nExample:\nMy model revealed a clear divide between smokers and non-smokers — so distinct that you could almost draw a line through the data. What began as a simple prediction task turned into an exploration of how lifestyle, age, and health risk shape real-world costs.\nPrompt:\nIn one or two sentences, describe your most interesting finding or surprise."
  },
  {
    "objectID": "posts/00_Example_structure/example.html#why-it-matters",
    "href": "posts/00_Example_structure/example.html#why-it-matters",
    "title": "Project Title",
    "section": "2. Why It Matters",
    "text": "2. Why It Matters\nSignificance? Explain the real-world relevance briefly.\nPredicting [target variable] isn’t just an academic challenge — it’s central to how [industry or people] make decisions about [outcome]. These insights help [who] [do what].\nPrompt:\nWhy does this [prediction / classification / model / analysis] matter? Who benefits or learns something from it? Why is this development important to the field or to users."
  },
  {
    "objectID": "posts/00_Example_structure/example.html#the-data",
    "href": "posts/00_Example_structure/example.html#the-data",
    "title": "Project Title",
    "section": "3. The Data",
    "text": "3. The Data\nDescribe the dataset briefly (size, features, target). Keep it to a single paragraph or short list. Include the most informative initial visualization (e.g., a distribution plot).\nExample:\nThe dataset contains [number] observations, each describing [what the rows represent]. Key features include [list 4–6 features briefly]. The target variable is [target], which ranges from [low] to [high].\nPrompt:\nDescribe dataset, main columns, and link if public. (Source: Dataset on Kaggle)"
  },
  {
    "objectID": "posts/00_Example_structure/example.html#what-i-did",
    "href": "posts/00_Example_structure/example.html#what-i-did",
    "title": "Project Title",
    "section": "4. What I Did",
    "text": "4. What I Did\nSummarize your workflow and models quickly.\nExample:\nThe workflow followed a simple pattern: EDA → Feature Engineering → Model Training → Evaluation. I cleaned categorical data, encoded features, and compared Linear Regression, Random Forest, and Gradient Boosting models. Performance was evaluated using MAE and R² scores.\nPrompt:\nSummarize your overall pipeline in 3–4 lines — from raw data to results. Write sentences about your process, models, and metrics."
  },
  {
    "objectID": "posts/00_Example_structure/example.html#what-i-found",
    "href": "posts/00_Example_structure/example.html#what-i-found",
    "title": "Project Title",
    "section": "5. What I Found",
    "text": "5. What I Found\nUse short bullet points or 3–5 sentences to highlight insights.\n• [Main insight 1]\n• [Main insight 2]\n• [Main insight 3]\n• [Performance comparison, if relevant]\nUse a table or bar chart from your notebook to compare model performance. Highlight the model that won and why. Focus on interpreting the model’s output (e.g., a feature importance plot).\nPrompt:\nWrite your top 3–5 findings or surprises. Mention trends, relationships, or model outcomes."
  },
  {
    "objectID": "posts/00_Example_structure/example.html#what-i-learned",
    "href": "posts/00_Example_structure/example.html#what-i-learned",
    "title": "Project Title",
    "section": "6. What I Learned",
    "text": "6. What I Learned\nReflect on the project — personal or technical takeaway.\nThis project reminded me that [lesson]. Even small datasets can reveal rich stories when you focus on [what]. I also learned that [technical or conceptual insight].\nPrompt:\nWhat did this project teach you about data, modeling, or problem-solving?"
  },
  {
    "objectID": "posts/00_Example_structure/example.html#whats-next",
    "href": "posts/00_Example_structure/example.html#whats-next",
    "title": "Project Title",
    "section": "7. What’s Next",
    "text": "7. What’s Next\nClose with momentum — a sentence about your next project or curiosity.\nNext, I plan to apply the same thinking to [next dataset/problem] — shifting from [type of task] to [type of task].\nPrompt:\nMention your upcoming project or what you want to explore next."
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#key-results",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#key-results",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "1. Key Results",
    "text": "1. Key Results\n\nCharges generally rise with age.\nSmokers consistently have higher and more variable charges than non-smokers.\n\n\n\n\nFig. 0 Showing the most important features identified by a Decision Tree Regressor.\n\n\n\n\n\n\n\n\n\n\n\nModels\nMAE\nMSE\nRMSE\nR2\n\n\n\n\n0\nLinearRegression\n4092.36\n31333268.50\n5597.61\n0.79\n\n\n1\nSVR\n3373.30\n37706594.68\n6140.57\n0.75\n\n\n2\nDecisionTreeRegressor\n2755.59\n21655894.86\n4653.59\n0.86\n\n\n3\nRandomForestRegressor\n2459.69\n18958974.55\n4354.19\n0.88"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#my-analysis",
    "href": "posts/02_Medical_Costs_Regression/blog_Regression_project.html#my-analysis",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "My Analysis",
    "text": "My Analysis\nHere is a long section of text and figures…"
  }
]