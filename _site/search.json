[
  {
    "objectID": "posts/02_Medical_Costs_Regression/Medical_Costs_Regression.html#key-results",
    "href": "posts/02_Medical_Costs_Regression/Medical_Costs_Regression.html#key-results",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "1. Key Results",
    "text": "1. Key Results\n\nCharges generally rise with age.\nSmokers consistently have higher and more variable charges than non-smokers.\n\n\n\n\nFig. 0 Showing the most important features identified by a Decision Tree Regressor.\n\n\n\n\n\n\n\n\n\n\n\nModels\nMAE\nMSE\nRMSE\nR2\n\n\n\n\n0\nLinearRegression\n4092.36\n31333268.50\n5597.61\n0.79\n\n\n1\nSVR\n3373.30\n37706594.68\n6140.57\n0.75\n\n\n2\nDecisionTreeRegressor\n2755.59\n21655894.86\n4653.59\n0.86\n\n\n3\nRandomForestRegressor\n2459.69\n18958974.55\n4354.19\n0.88"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/Medical_Costs_Regression.html#why-it-matters",
    "href": "posts/02_Medical_Costs_Regression/Medical_Costs_Regression.html#why-it-matters",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "2. Why It Matters",
    "text": "2. Why It Matters\nPredicting medical costs isn’t just a math problem — it’s about understanding the real price of our health choices. For insurers, these predictions guide fairer pricing and risk assessment. For individuals, they reveal how habits like smoking or maintaining a healthy BMI can shape future expenses. In a world where healthcare costs can make or break financial stability, this kind of model helps turn data into smarter, more informed decisions."
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/Medical_Costs_Regression.html#the-data",
    "href": "posts/02_Medical_Costs_Regression/Medical_Costs_Regression.html#the-data",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "3. The Data",
    "text": "3. The Data\nThe dataset comes from the Medical Cost Personal Dataset on Kaggle, containing 1,338 observations, each representing a single U.S. health insurance policyholder. Key features include age, sex, BMI, number of children, smoker status, and region. The target variable, charges, captures each person’s annual medical cost, ranging from about $1,000 to over $60,000. Despite its small size, the dataset offers rich insights into how lifestyle and demographics drive healthcare expenses.\n\n\n\nFig. 1 Shows the Distribution of Numeric Features in the Medical Costs Dataset\n\n\n\n\n\nFig. 2 Shows the Distribution of Categorical Features in the Medical Costs Dataset"
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/Medical_Costs_Regression.html#what-i-did",
    "href": "posts/02_Medical_Costs_Regression/Medical_Costs_Regression.html#what-i-did",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "4. What I Did",
    "text": "4. What I Did\nExplored the medical cost dataset with visuals — distributions, correlations, and feature effects — to link age, BMI, and smoking to charges. Cleaned numeric features with StandardScaler and categorical variables with OneHotEncoder. Trained LinearRegression, SVR, DecisionTreeRegressor, and RandomForestRegressor, tuning hyperparameters with RandomizedSearchCV. Evaluated MAE, MSE, RMSE, and R² on the test set and compared models visually."
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/Medical_Costs_Regression.html#what-i-found",
    "href": "posts/02_Medical_Costs_Regression/Medical_Costs_Regression.html#what-i-found",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "5. What I Found",
    "text": "5. What I Found\nInsurance charges tend to increase with age. Smokers have significantly higher and more variable charges compared to non-smokers, whose costs show a smoother, more consistent trend.\nAmong smokers, insurance charges generally increase with higher BMI, while BMI has little impact on costs for non-smokers. Within non-smokers, age drives costs.\nFeature importance analysis (from the tree-based models) highlighted smoking, age, and BMI as the top predictors — confirming both domain expectations and model consistency.\nThe Random Forest Regressor achieved the best results, with the lowest RMSE (≈ 4354) and highest R² (≈ 0.88), indicating strong predictive accuracy and generalization on unseen data, showing that it is possible to predict medical costs based on key personal and lifestyle factors. This demonstrates that data-driven models can effectively capture the underlying relationships between health behaviors and medical expenses, enabling more accurate cost forecasting and better-informed healthcare and policy decisions.\n\n\n\nFig. 3 Charges increase with age, and smokers have significantly higher and more variable charges than non-smokers.\n\n\n\n\n\nFig. 4 Smokers consistently have higher charges than non-smokers. Among smokers, charges increase strongly with BMI (r ≈ 0.81), while among non-smokers, BMI has almost no relationship with charges (r ≈ 0.08). This indicates a strong interaction effect — smoking amplifies the impact of BMI on charges.\n\n\n\n\n\nFig. 5 Decision tree regression model predicting medical insurance charges. The model splits data points into groups based on key factors. The most important splitting criterion is smoking status. Among non-smokers, age is the most influential variable, while for smokers, BMI plays the dominant role. The “value” shown in each node represents the model’s predicted target value (here, the estimated insurance cost in dollars).\n\n\n\n\n\nFig. 6 Comparison of Root Mean Squared Error (RMSE) values for different regression models on the test set. The RMSE measures the average magnitude of prediction errors, with lower values indicating better model performance. The Random Forest Regressor achieved the lowest RMSE, followed by the Decision Tree Regressor, while the SVR and Linear Regression models showed higher error levels, suggesting less accurate predictions.)\n\n\n\n\n\nFig. 7 Comparison of R² scores for different regression models on the test set. The R² score represents the proportion of variance in medical insurance charges explained by each model. Higher values indicate better predictive performance. The Random Forest Regressor achieved the highest R², followed closely by the Decision Tree Regressor, while Linear Regression and SVR showed comparatively lower explanatory power."
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/Medical_Costs_Regression.html#what-i-learned",
    "href": "posts/02_Medical_Costs_Regression/Medical_Costs_Regression.html#what-i-learned",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "6. What I Learned",
    "text": "6. What I Learned\nModel performance improved with complexity:\nTree-based models, especially Random Forest, captured the nonlinear impact of health and lifestyle factors most effectively. The findings align with real-world intuition — smokers and older individuals face substantially higher insurance costs."
  },
  {
    "objectID": "posts/02_Medical_Costs_Regression/Medical_Costs_Regression.html#whats-next",
    "href": "posts/02_Medical_Costs_Regression/Medical_Costs_Regression.html#whats-next",
    "title": "Predicting Medical Costs - A Regression Problem",
    "section": "7. What’s Next",
    "text": "7. What’s Next\nThis project shows that predicting medical costs is possible — but there’s room to grow. Future work could explore more advanced models like Gradient Boosting or XGBoost to see if they capture even subtler patterns in the data. Another direction is adding richer features to improve model depth and realism. Finally, scaling this work to larger, more diverse datasets would help assess how well these findings hold up across different populations. The next steps are open — it’s up to you to take this foundation and push it further."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Topics",
    "section": "",
    "text": "Hello Blog!\n\n\n\n\n\n\n\n\nOct 25, 2025\n\n\nPatrick Linke\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\n\n\nPredicting Medical Costs - A Regression Problem\n\n\n\nRegression\n\nMedicine\n\n\n\n\n\n\n\n\n\nOct 27, 2025\n\n\nPatrick Linke\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "contact.html#lets-connect",
    "href": "contact.html#lets-connect",
    "title": "Contact",
    "section": "Let’s Connect",
    "text": "Let’s Connect\nI’d love to connect with fellow machine learning enthusiasts, especially those interested in healthcare applications and data science.\n\nLinkedIn: My LinkedIn Profile\nGitHub: My GitHub Profile\n\n\nAlways happy to chat about ML, medicine, and the intersection of both!"
  },
  {
    "objectID": "about.html#who-am-i",
    "href": "about.html#who-am-i",
    "title": "About Me",
    "section": "Who am I?",
    "text": "Who am I?\nHi, I’m Patrick — a medical student fascinated by how machine learning and artificial intelligence are reshaping healthcare.\nThis blog is where I document my journey — learning, experimenting, and sharing insights as I explore how data and algorithms can improve decision-making."
  },
  {
    "objectID": "about.html#why-this-blog-exists",
    "href": "about.html#why-this-blog-exists",
    "title": "About Me",
    "section": "Why This Blog Exists",
    "text": "Why This Blog Exists\nThis blog represents my commitment to learning in public—documenting my journey as I build hands-on projects and deepen my understanding of machine learning. Here’s what drives me:\n\nBridging domains: Exploring how machine learning can enhance medical research and clinical practice\nBuilding intuition: Working through real datasets to understand algorithms beyond theory\nSharing knowledge: Helping fellow learners see practical workflows and honest reflections\nContinuous growth: Documenting failures and successes as part of the learning process"
  },
  {
    "objectID": "about.html#what-youll-find-here",
    "href": "about.html#what-youll-find-here",
    "title": "About Me",
    "section": "What You’ll Find Here",
    "text": "What You’ll Find Here\nThis isn’t a tutorial site — it’s a documentation of my learning process. Each post represents a step in my understanding of machine learning, from data preprocessing to model evaluation and interpretation.\nCurrent Focus Areas:\n\nMedical data analysis and prediction\nClassical machine learning algorithms\nFeature engineering and selection\nModel interpretation and validation"
  },
  {
    "objectID": "about.html#my-approach",
    "href": "about.html#my-approach",
    "title": "About Me",
    "section": "My Approach",
    "text": "My Approach\nI focus on:\n\nPractical projects with real-world datasets\nClear explanations of methods and reasoning\nVisual storytelling through charts and analysis\nReproducible code that others can learn from\nHonest documentation of challenges and insights"
  },
  {
    "objectID": "about.html#start-here",
    "href": "about.html#start-here",
    "title": "About Me",
    "section": "Start Here",
    "text": "Start Here\nYou can start here or explore the Blog! Have fun!"
  },
  {
    "objectID": "about.html#lets-connect",
    "href": "about.html#lets-connect",
    "title": "About Me",
    "section": "Let’s Connect",
    "text": "Let’s Connect\nI’d love to connect with fellow machine learning enthusiasts, especially those interested in healthcare applications:\n\nLinkedIn: My LinkedIn Profile\nGitHub: My GitHub Profile\n\n\nLearning in public. Bridging medicine and machine learning. Sharing the journey one project at a time."
  },
  {
    "objectID": "home.html",
    "href": "home.html",
    "title": "Intelligent Machines",
    "section": "",
    "text": "Getting Started\n\n\n\nCheck out my latest projects in the Blog section, where I share complete workflows, code, and insights from working with real datasets.\n\n\n\nWelcome to my learning-in-public journal where I document my journey through applied machine learning. Here, you’ll find more information about this blog.\n\nLearning in public • Building understanding • Sharing insights"
  },
  {
    "objectID": "home.html#recent-posts",
    "href": "home.html#recent-posts",
    "title": "Intelligent Machines",
    "section": "",
    "text": "Check out my latest projects in the Blog section, where I share complete workflows, code, and insights from working with real datasets."
  },
  {
    "objectID": "home.html#exploring-machine-learning-through-real-data",
    "href": "home.html#exploring-machine-learning-through-real-data",
    "title": "Intelligent Machines",
    "section": "",
    "text": "Welcome to my learning-in-public journal where I document my journey through applied machine learning. Here, you’ll find more information about this blog.\n\nLearning in public • Building understanding • Sharing insights"
  },
  {
    "objectID": "posts/01_Welcome/Hello_Blog.html",
    "href": "posts/01_Welcome/Hello_Blog.html",
    "title": "Hello Blog!",
    "section": "",
    "text": "Hello and Welcome to My Blog!\nI decided to start this blog to document my machine learning journey in public.\nI am fascinated by idea of building intelligent machines that can learn from data and help make better decisions - especially in fields where precision matters and the cost of errors is high.\nI’m a medical student, so the content will often feature medical topics. But beyond that, I’ll explore whatever I find interesting and intriguing at the moment and share what I learn along the way.\n\n\nJust Read Along\nNot everyone wants — or needs — to write code, and that’s perfectly fine.\nYou can still enjoy this blog by reading along, exploring the visuals, and following my explanations.\nThe goal is to make complex ideas intuitive, whether you’re coding beside me or just curious about how it all works.\n\n\nHow You Can Code Along\nIf you’d like to try the code yourself, you can download my notebooks and run the directly in Google Colab or on Kaggle — no installation required!\nOf course, you can also type along without downloading the notebooks.\nI highly encourage you to experiment with the code — this is one of the best learning experiences you’ll have!\nIf you get stuck or have any questions, feel free to reach out to my via the Contact page or ask an LLM :).\nIn general, ChatGPT, Claude, Gemnini, and similar models are great at explaining code, so feel free to use them to enhance your learning experience!\nThat said, there’s no pressure to code along. You can absolutely enjoy this blog by simply reading the posts, exploring the visuals, and following the explanations.\nEven without writing code, you’ll still get insights into how machine learning works in practice.\n\n\nProgramming Language and Libraries\nThe code will be written in Python, a programming language that’s been around since 1991.\nPython is great for data science, statistics, automation, machine learning and AI. It makes it easy to build prototypes and MVPs quickly. It is also fairly easy to learn, so I encourage you to check it out if any of the topics sound interesting.\nCore libraries I’ll use:\n\nNumpy — fundamental package for scientific computing\n\nPandas — data analysis and manipulation of tabular data\n\nMatplotlib.pyplot — plotting figures and creating visualizations\n\nSeaborn — advanced statistical plotting\nScikit-Learn — classical machine learning algorithms\n\n\n\nThanks for Reading This First Post!\nIf you’d like to know more about me and why I started this blog, check out the About page. Otherwise, dive into the next post and have fun!\nThis is just the beginning. Let’s see where curiosity — and a bit of code — takes us.\n\n\nCredits\nP.S. The image at the beginning of this post was inspired by @EdDonner’s fantastic course on AI Agents!\nWhile the style was inspired by the course, I created the final image myself using an AI model based on my own instructions."
  }
]