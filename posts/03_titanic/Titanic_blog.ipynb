{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "780fa0b4",
   "metadata": {},
   "source": [
    "---\n",
    "title: Who Survived the Titanic? A Data-Driven Look at Chance, Class, and Choice\n",
    "author: Patrick Linke\n",
    "date: 2025-11-02\n",
    "categories: [\"Classification\"]\n",
    "execute: false\n",
    "image: images/Titanic_sideview.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd4cd62",
   "metadata": {},
   "source": [
    "![](images/Titanic_sideview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6524b502",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d1e420",
   "metadata": {},
   "source": [
    "## 1 Key Results\n",
    "\n",
    "Who survived the **Titanic** shipwreck — and why? Beneath this tragic event lies a fascinating data story of class, age, and gender.\n",
    "\n",
    "Through **Exploratory Data Analysis (EDA)** and **machine learning**, I built models to predict passenger survival and uncover the hidden patterns behind the numbers. While the **overall survival** rate was only about 38%, survival wasn’t random — *women*, *children*, and *first-class passengers* had dramatically higher chances. This project became a hands-on introduction to **classification modeling** and key evaluation metrics like **Precision**, **Recall**, and **F1-Score**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9f1ee0",
   "metadata": {},
   "source": [
    "![Fig. 1 Shows the Accuracy scores of different Baseline Models, along with a box plot highlighting the lower and upper quartiles, and \"whiskers\" showing the extent of the scores. The SVM was then selected for fine-tuning and evaluating Performance Metrics.](images/classification/accuracy%20by%20model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55194b25",
   "metadata": {},
   "source": [
    "![](images/classification/SR%20by%20age%20and%20gender.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b359561",
   "metadata": {},
   "source": [
    "## 2. Why It Matters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4918d2",
   "metadata": {},
   "source": [
    "Predicting survival in the Titanic disaster dataset isn’t just an academic challenge — it’s central to how we think about risk, fairness and decision-making in real-world scenarios. When we study what factors (such as gender, class, age) determined survival, these insights help policy makers, emergency planners and data scientists to better design protocols that save lives in future crises.\n",
    "\n",
    "By applying Exploratory Data Analysis (EDA) and machine learning techniques to this classification problem, we learn not only how to build models that predict outcomes, but also why those outcomes occurred. That matters because in the fields of transportation safety, disaster response and social equity, it’s not enough to know who survived — we want to understand why. These learnings help organisations and analysts make informed decisions around resource allocation, training and evacuation strategies — ultimately leading to safer systems and more equitable responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d01f9",
   "metadata": {},
   "source": [
    "## 3. The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9321c0e3",
   "metadata": {},
   "source": [
    "The dataset from the Kaggle competition “Titanic – Machine Learning from Disaster” consists of a training set of 891 passenger records and a test set of 418 records. Each row describes a passenger on the RMS Titanic and includes features such as:\n",
    "\n",
    "- Ticket class: 1st, 2nd, 3rd\n",
    "- Sex (male or female)\n",
    "- Age (in years)\n",
    "- Number of siblings/spouses aboard\n",
    "- Number of parents/children aboard\n",
    "- Ticket fare paid\n",
    "- Port of embarkation: Cherbourg/Queenstown/Southampton\n",
    "\n",
    "The target variable is Survived (0 = died, 1 = survived) for each passenger in the training set.\n",
    "\n",
    "Link to the public dataset: https://www.kaggle.com/competitions/titanic/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce0875a",
   "metadata": {},
   "source": [
    "![Fig. 2 Shows the Distribution of the Features in the Dataset. Port of Embarkation: C = Cherbourg, Q = Queenstown, S = Southampton](images/classification/Distribution_of_features.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17300a6",
   "metadata": {},
   "source": [
    "![Fig. 3 Distribution of the Target. Overall Survival Rate is ~38%](images/classification/survivors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f58b1",
   "metadata": {},
   "source": [
    "# Methods & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cdfcc4",
   "metadata": {},
   "source": [
    "## 4. What I Did"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa1407",
   "metadata": {},
   "source": [
    "The workflow followed a straightforward pattern: **EDA** → **Feature Engineering** → **Model Training** → **Evaluation**.\n",
    "\n",
    "During feature engineering, I created meaningful variables such as AgeGroup (Child, Teen, Young Adult, Adult, Senior), cabin_present (indicating whether a cabin number was available), and RelativesOnboard (the sum of SibSp and Parch).\n",
    "\n",
    "I trained several baseline models — **SGD**, **SVM**, **Decision Tree**, and **Random Forest** — and compared their performance using **accuracy**. The **SVM** model performed best, so I fine-tuned it with **GridSearchCV** to optimize hyperparameters.\n",
    "\n",
    "Final performance was evaluated using **Accuracy**, **Precision**, **Recall**, and **F1-Score** to ensure balanced assessment across all prediction outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c7820b",
   "metadata": {},
   "source": [
    "## 5. What I Found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5327d77f",
   "metadata": {},
   "source": [
    "Influence of Features on **Survival Rates**\n",
    "\n",
    "- **Gender** was the single strongest predictor of survival. Females had consistently higher survival probabilities (~0.59–0.94), while males saw a steep drop after childhood (~0.09–0.23).\n",
    "\n",
    "- **Passenger Class** clearly stratified outcomes — higher class meant better chances. The extremes: 1st-class females (~0.97 survival) vs 3rd-class males (~0.14).\n",
    "\n",
    "- **Age** mattered: children were prioritized during evacuation. Boys and girls under 12 had similar survival rates (~0.57–0.59), but after adolescence, the gender gap widened sharply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1d0e11",
   "metadata": {},
   "source": [
    "![Fig. 4 Survival Rate by Passenger Class and Gender. Gender dominates survival: females outlive males in every class. Class amplifies it: higher class → higher survival for both genders.](images/classification/SR%20by%20Class%20and%20Gender.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b686da20",
   "metadata": {},
   "source": [
    "![Fig. 5 Survival Rate by Age and Gender. Clear “women and children first” pattern; gender dominates age once past childhood. Strong gender effect: females had high survival across ages (~0.59–0.94), males low after childhood (~0.09–0.23). Children were prioritized: boys and girls had similar, relatively high survival.](images/classification/SR%20by%20age%20and%20gender.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5673e0f",
   "metadata": {},
   "source": [
    "**Performance Metrics of the Best Model** (SVM):\n",
    "- Accuracy 82%\n",
    "- Precision: 80%\n",
    "- Recall: 72%\n",
    "- F1-Score: 76%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cebdf17",
   "metadata": {},
   "source": [
    "![Fig. 6 Precision-Recall Curve of the SVM Model.](images/classification/precision_recall_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f9edfc",
   "metadata": {},
   "source": [
    "![Fig. 7 ROC Curve of the SVM Model. AUC = 0.83.](images/classification/roc_curve_svm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc5641d",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53279939",
   "metadata": {},
   "source": [
    "## 6. What I Learned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4492ec",
   "metadata": {},
   "source": [
    "This project taught me how to build and evaluate C**lassification Models** end to end — from preprocessing raw data to fine-tuning hyperparameters. I deepened my understanding of key evaluation metrics such as **Accuracy**, **Precision**, **Recall**, **F1-Score**, and the **Confusion Matrix**, as well as diagnostic tools like the **Precision-Recall** and **ROC Curves**.\n",
    "\n",
    "Through **EDA** and thoughtful feature engineering, I saw how data visualization and preprocessing pipelines can transform raw numbers into insights that explain why models make certain predictions — not just how well they perform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb66ccb",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "**Thanks for Reading the Post!**\n",
    "\n",
    "Inspired by Chapter 3 from [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 3rd Edition by Aurélien Géron](https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c510fcd0",
   "metadata": {},
   "source": [
    "<a href=\"../../downloads/Titanic_classification_notebook.ipynb\" download class=\"btn btn-primary\">\n",
    "  ⬇️ Download The Notebook\n",
    "</a>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
